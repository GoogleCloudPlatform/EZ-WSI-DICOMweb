{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9swiCsR_grx"
      },
      "source": [
        "\u003ctable class=\"tfo-notebook-buttons\" align=\"left\"\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://colab.sandbox.google.com/github/Google-Health/imaging-research/blob/master/path-foundation/linear-classifier-demo.ipynb\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" /\u003eRun in Google Colab\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd\u003e\n",
        "    \u003ca target=\"_blank\" href=\"https://github.com/Google-Health/imaging-research/tree/master/path-foundation\"\u003e\u003cimg src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" /\u003eView source on GitHub\u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/table\u003e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCy7vXMN73tI"
      },
      "source": [
        "~~~\n",
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "~~~\n",
        "# Getting Started Guide For Generating Pathology Embeddings\n",
        "\n",
        "This notebook contains a series of examples covering a range of situations for generating Google [Digital Pathology embeddings](https://research.google/blog/health-specific-embedding-tools-for-dermatology-and-pathology/). Each example is standalone, and you are free to jump around.\n",
        "\n",
        "## Use of EZ-WSI\n",
        "\n",
        "This notebook leverages [EZ-WSI DICOMweb](https://github.com/GoogleCloudPlatform/EZ-WSI-DICOMweb), which makes it easier to work with DICOM data and generate embeddings from a variety of data sources: [DICOM store](https://cloud.google.com/healthcare-api/docs/how-tos/dicom), [Google Cloud Storage](https://cloud.google.com/storage?hl=en), and  locally using files or in memory representations.\n",
        "\n",
        "## Use of Google Research Digital Pathology Embedding API\n",
        "\n",
        "To make these examples simpler and more performant, they commonly use the Google Research Digital Pathology Embedding API.\n",
        "\n",
        "Using this API allows us to streamline the examples and not force you to spin up your own serving environment. You are always free to use EZ-WSI with local files or your own serving container. Access to the Embedding API is available by [allow list](https://github.com/Google-Health/imaging-research/tree/master/path-foundation#access-options).\n",
        "\n",
        "On performance, using the Embedding API (or your own spun up instance) accelerates embedding generation for data stored within Cloud by enabling the embedding generation endpoint to directly connect and retrieve the imaging data required for the embedding generation. Doing this enables the source imaging to be retrieved at much greater efficiency using the Google datacenter network and removes the cost and time required for users of the API to retrieve and then transmit giga-pixel imaging to the embedding endpoints. Data retrieved by the endpoints is used only for embedding generation; \u003cu\u003edata is not retained\u003c/u\u003e. Source code and the terraform infrastructure as code (IAC) required to deploy an embedding endpoint will be made available via open source.\n",
        "\n",
        "The Embeddings API generates pathology embeddings from image patches, cropped sub-regions of a digital pathology image. Higher level ML will typically bring together embeddings from many patches sampled across a region of interest or the entire slide to produce a prediction. EZ-WSI provides interfaces to easily define patches and retrieve embeddings. This co-lab will step through a number of contained examples. Each example will stand alone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drB6arWi4PKv"
      },
      "source": [
        "# EZ-WSI Patches\n",
        "\n",
        "The embedding generation interfaces built into EZ-WSI are designed to make it easy to transform image patches into embeddings. EZ-WSI provides mechanisms to define image patches for imaging stored within a DICOM store, on Google Cloud Storage, or from local data sources. At their core EZ-WSI patches are light-weight and describe only the parameters necessary to access the pixel information described by a patch. When referencing data stored in the Cloud , pixel data is retrieved only when necessary, e.g., when image bytes are accessed. The Cloud Embedding API (e.g., V2PatchEmbeddingEndpoint) is based around this same concept, the embedding API accepts requests that define data stored within Cloud. To fulfill the request the Cloud endpoint will then retrieve the necessary data and generate the embedding and return the results. Together this enables clients using EZ-WSI to efficiently generate large and complex requests for patch embeddings. In the example colabs, the image bytes associated with patches are accessed, this done demonstration purposes only, to visualize the image bytes from which the embeddings are being generated, and is not required for patch embedding generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbiy-Tcrz5HK"
      },
      "outputs": [],
      "source": [
        "# @title Pip install EZ-WSI DICOMweb\n",
        "%%capture\n",
        "!pip install --upgrade ez_wsi_dicomweb\u003e=6.0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDcvKH_6z5HK"
      },
      "source": [
        "**Colab specific code to authenticate colab and display patch imaging .**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Cx6AHODBpk1"
      },
      "outputs": [],
      "source": [
        "from typing import Union\n",
        "from ez_wsi_dicomweb import dicom_slide\n",
        "from ez_wsi_dicomweb import gcs_image\n",
        "from google.colab import auth\n",
        "import matplotlib.pyplot as plt\n",
        "# Authenticate user for access. There will be a popup asking you to sign in with your user account and approve access.\n",
        "auth.authenticate_user()\n",
        "\n",
        "def render_patch(patch: Union[dicom_slide.DicomPatch, gcs_image.GcsPatch], plot_name: str = '') -\u003e None:\n",
        "  patch_bytes = patch.image_bytes()\n",
        "  if len(patch_bytes.shape) == 2 or (\n",
        "      len(patch_bytes.shape) == 3 and patch_bytes.shape[-1] == 1\n",
        "      ):\n",
        "    mem = np.zeros((224, 224, 3), dtype=patch_bytes.dtype)\n",
        "    mem[..., np.arange(3)] = patch_bytes[...]\n",
        "    patch_bytes = mem\n",
        "  print(patch_bytes.shape)\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.imshow(patch_bytes)\n",
        "  plt.title(plot_name)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4PEqQTZrEGf"
      },
      "source": [
        "# Computing Embeddings For Single Patch\n",
        "\n",
        "The examples that follow illustrate how to use EZ-WSI to generate embeddings using the Pathology Embeddings API for a single patch from a DICOM image, image stored on Google Cloud Storage, and from an in memory representation. All examples accomplish this using the \u003cu\u003eget_patch_embedding\u003c/u\u003e function.\n",
        "\n",
        "***Performance-Tip:***\n",
        "\n",
        "The get_patch_embedding function is the simplest patch-to-embedding interface. When embeddings are needed from multiple patches then embedding generation efficiency can be \u003cu\u003egreatly increased\u003c/u\u003e by generating the embeddings in batch using either the generate_patch_embeddings function or the PatchEmbeddingSequence class.\n",
        "\n",
        "```\n",
        "def get_patch_embedding(\n",
        "    endpoint: patch_embedding_endpoints.AbstractPatchEmbeddingEndpoint,\n",
        "    patch: patch_embedding_types.EmbeddingPatch,\n",
        "    ensemble_method: Optional[\n",
        "        patch_embedding_ensemble_methods.PatchEnsembleMethod\n",
        "    ] = None,\n",
        ") -\u003e np.ndarray:\n",
        " ```\n",
        "\n",
        "Get patch embeddings function accepts the following parameters:\n",
        "\n",
        "- \u003cu\u003eendpoint\u003c/u\u003e: Is the abstraction interface through which EZ-WSI communicates with the various embedding model VertexAI endpoints and or local execution. See [endpoints](endpoints) for more information.\n",
        "\n",
        "- \u003cu\u003ePatch\u003c/u\u003e: A patch is patches are cropped sub regions from a DICOM WSI pyramid layer, a slide microscopy image, a or a traditional image stored either on Google Cloud Storage, or from local data source.\n",
        "\n",
        "- \u003cu\u003eensemble_method\u003c/u\u003e: Ensemble methods are optional and enable EZ-WSI to generate embeddings for patches which exceed the embedding dimensions of the endpoint. If not provided, input patches must match the input width and height dimensions of the endpoint. See [ensemble methods](ensemble_method) for more information.\n",
        "\n",
        "**Returns:**\n",
        "\n",
        "Numpy array containing patch imaging embedding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeclcXSWphLG"
      },
      "source": [
        "## Example: Generating a Single Patch Embedding from a DICOM Image Stored in the Google DICOM Store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCCYlzPChsFO"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import dicom_web_interface\n",
        "from ez_wsi_dicomweb import dicom_slide\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import ez_wsi_dicomweb.ml_toolkit.dicom_path as dicom_path\n",
        "\n",
        "# Defines DICOM image stored within a Google DICOM store.\n",
        "DATASET_PROJECT_ID = 'hai-cd3-foundations'\n",
        "DATASET_LOCATION = 'us-west1'\n",
        "DATASET_ID = 'pathology'\n",
        "STORE_ID  = 'camelyon'\n",
        "STUDY_INSTANCE_UID  = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461'\n",
        "SERIES_INSTANCE_UID = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463'\n",
        "\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging.\n",
        "series_path = dicom_path.FromString(f'https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}')\n",
        "\n",
        "# Crediental factory that provides EZ-WSI with credentials to access DICOM imaging metadata.\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide, retrieves slide metadata but not slide imaging.\n",
        "ds = dicom_slide.DicomSlide(path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf))\n",
        "\n",
        "# Request a single patch of imaging from the highest magnfication.\n",
        "patch = ds.get_patch(level=ds.native_level, x=43000, y=10000, width=224, height=224)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (Not required purely to illustrate source imaging for embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in embeding\n",
        "print (embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFzwoTiwHRTN"
      },
      "source": [
        "## Example: Generating an Single Patch Embedding from a Traditional Image Stored in Google Cloud Storage\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyK7BX01p49o"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "\n",
        "\n",
        "# Create a reference to an image stored on Google Cloud Storage\n",
        "# By default authenticates with default credientals.\n",
        "image = gcs_image.GcsImage('gs://healthai-us/pathology/example_large_patch.jpeg',\n",
        "                           credential_factory=credential_factory.NoAuthCredentialsFactory())\n",
        "\n",
        "# Define coordinates of image patch\n",
        "patch = image.get_patch(x=10, y=10, width=224, height=224)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (Not required purely to illustrate source imaging for embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in embeding\n",
        "print (embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEJsLaCUhNa-"
      },
      "source": [
        "## Example: Generating an Single Patch Embedding from In Memory Numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_wez6RRhvSK"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import local_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Create a in memory uncompressed v\n",
        "memory = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "\n",
        "# Construct an image from the in memory patch\n",
        "image = local_image.LocalImage(memory)\n",
        "\n",
        "# Define coordinates of image patch\n",
        "patch = image.get_patch(x=0, y=0, width=224, height=224)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (Not required purely to illustrate source imaging for embedding)\n",
        "render_patch(patch, 'Image is expected to be entirely black')\n",
        "\n",
        "# Display first 12 values in embeding\n",
        "# Embeddings will match previous same image bytes\n",
        "# but from local sourceembeddings.\n",
        "print (embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBziwNTgjZlF"
      },
      "source": [
        "# Resizing Embedding Source Imaging Dimensions\n",
        "\n",
        "It is not uncommon that Digital Pathology ML performs best when executed on imaging encoded at an optimal pixel spacing / magnification (e.g. 20x). However, for a variety of reasons, imaging may not be stored within cloud sources (e.g., [DICOM Store,](https://cloud.google.com/healthcare-api/docs/how-tos/dicom) [Google Cloud Storage](https://cloud.google.com/storage?hl=en)) or locally at these optimial magnifications. The Pathology Embedding API enables source imaging to be retrieved and resampled on the embedding endpoint to match a desired target magnification prior to embedding generation.\n",
        "\n",
        "The pathology API requires that input for patch embeddings match the input dimensions of embedding endpoints. The pathology embedding endpoints generate  embedding for patches that are 224 x 224 pixels. EZ-WSI provides patch embedding ensemble methods to work around these limitations and enable embeddings to be generated for patches of nearly any dimension. However, image resizing can also be used as an alternative to generate embeddings for image patches that would otherwise not match the embedding endpoint input requirements.\n",
        "\n",
        "The mechanisms that EZ-WSI uses to define and rescale patch source imaging dimensions are slightly different for images stored on a DICOM store and for images stored on Google Cloud Storage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwDoZmlprPH"
      },
      "source": [
        "## Example: Resizing DICOM Imaging at the Embedding Endpoint Prior to Embedding Generation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QCn7x_qr5mc"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import dicom_web_interface\n",
        "from ez_wsi_dicomweb import dicom_slide\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import ez_wsi_dicomweb.ml_toolkit.dicom_path as dicom_path\n",
        "\n",
        "# Defines DICOM image stored within a Google DICOM store.\n",
        "DATASET_PROJECT_ID = 'hai-cd3-foundations'\n",
        "DATASET_LOCATION = 'us-west1'\n",
        "DATASET_ID = 'pathology'\n",
        "STORE_ID  = 'camelyon'\n",
        "STUDY_INSTANCE_UID  = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461'\n",
        "SERIES_INSTANCE_UID = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463'\n",
        "\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging.\n",
        "series_path = dicom_path.FromString(f'https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}')\n",
        "\n",
        "# Crediental factory that provides EZ-WSI with credentials to access DICOM imaging metadata.\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide, retrieves slide metadata but not slide imaging.\n",
        "ds = dicom_slide.DicomSlide(path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf))\n",
        "\n",
        "# Resizes source imaging native_level to defined target dimensions that 4x\n",
        "# smaller.\n",
        "resized_level = ds.native_level.resize(dicom_slide.ImageDimensions(ds.native_level.width // 4, ds.native_level.height // 4))\n",
        "\n",
        "# Request a single patch of imaging from the resized level.\n",
        "# Generating the resized level will require the backend server fetch 16\n",
        "# frames (4^2) when generating the embedding. The V1 and V2 endpoints support up\n",
        "# to 8x server resampling.\n",
        "#\n",
        "# Important: Patch coordinates are defined in the coordinate system of the\n",
        "# of the resized image. In the example here the image is downsampled 4x to\n",
        "# and so source imaging patch coordinates are also scaled down 4x\n",
        "patch = ds.get_patch(level=resized_level, x=43000//4, y=10000//4, width=224, height=224)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (Not required purely to illustrate source imaging for embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in embeding\n",
        "print (embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llgDBEVctsqc"
      },
      "source": [
        "## Example: Resizing Google Cloud Storage Imaging at the Embedding Endpoint Prior to Embedding Generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od1D9CMTuo2v"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "\n",
        "\n",
        "# Defines image dimensions for GCS Image.\n",
        "image_dimensions = gcs_image.ImageDimensions(224, 224)\n",
        "\n",
        "# Create a reference to an image stored on Google Cloud Storage\n",
        "# By default authenticates with default credientals.\n",
        "#\n",
        "# Passing the optional image dimensions parameter into the GcsImage constructor\n",
        "# instructs the GcsImage to resize the image to the desired target dimensions.\n",
        "image = gcs_image.GcsImage('gs://healthai-us/pathology/example_large_patch.jpeg',\n",
        "                           image_dimensions=image_dimensions,\n",
        "                           credential_factory=credential_factory.NoAuthCredentialsFactory())\n",
        "\n",
        "# Define coordinates of image patch\n",
        "patch = image.get_patch(x=0, y=0, width=224, height=224)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (Not required purely to illustrate source imaging for embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in embeding\n",
        "print (embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjes_uX1vt6j"
      },
      "source": [
        "## Example: Resizing a Local Image Prior to Embedding Generation\n",
        "\n",
        "Imaging defined from a local data source (memory or file). Similar to the imaging stored on Google Cloud Storage source local data can be resized. In contrast to data stored on cloud, local data is rescaled prior to sending the data to the cloud embedding endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG32VJfNyHXz"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import local_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Create a in memory uncompressed image, white X on black background.\n",
        "memory = np.zeros((224*10, 224*10, 3), dtype=np.uint8)\n",
        "for y, x in zip(range(memory.shape[0]), range(memory.shape[1])):\n",
        "  memory[y, x-3:x+4, :] = 255\n",
        "  flipped_x =  memory.shape[1] - x - 1\n",
        "  memory[y, flipped_x-3:flipped_x+4, :] = 255\n",
        "\n",
        "# Defines image dimensions for GCS Image.\n",
        "image_dimensions = gcs_image.ImageDimensions(224, 224)\n",
        "\n",
        "# Create a reference to an image stored on Google Cloud Storage\n",
        "# By default authenticates with default credientals.\n",
        "#\n",
        "# Passing the optional image dimensions parameter into the LocalImage constructor\n",
        "# instructs the LocalImage to resize the image to the desired target dimensions.\n",
        "image = local_image.LocalImage(memory, image_dimensions=image_dimensions)\n",
        "\n",
        "# Define coordinates of image patch\n",
        "patch = image.get_patch(x=0, y=0, width=224, height=224)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch)\n",
        "\n",
        "# Display image (Not required purely to illustrate source imaging for embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in embeding\n",
        "print (embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgvG-oQZhdgt"
      },
      "source": [
        "# Generating Embeddings In Batch\n",
        "\n",
        "When embeddings are required for multiple patches the time required for embedding generation can be greatly reduced by requesting the embeddings in batch from cloud data sources. The EZ-WSI provides general purpose interfaces for batch embedding generation. These methods accept an iterator or sequence of patches. Patches sampled from the same source are grouped, embedding requests are parallelized both at request generation and on the backend endpoints.\n",
        "\n",
        "***Performance-Tip:***\n",
        "\n",
        "The batching performance optimizations require that patches sampled from  the same source, e.g., WSI pyramid layer, DICOM image, natural world image, or local data  source should be clustered in the input iterator or sequence by data source; each pyramid layer of a DICOM slide is considered a unique data source. If requested at random the performance of batch requests will degrade to that of the individual patch requests.\n",
        "\n",
        "***Embedding Generator***\n",
        "\n",
        "The patch embedding generator is the most flexible batching mechanism. The generator accepts either an iterator or sequence of patches and yields an EmbeddingResult for each input patch.\n",
        "\n",
        "```\n",
        "def generate_patch_embeddings(\n",
        "    endpoint: patch_embedding_endpoints.AbstractPatchEmbeddingEndpoint,\n",
        "    patches: Union[\n",
        "        Sequence[patch_embedding_types.EmbeddingPatch],\n",
        "        Iterator[patch_embedding_types.EmbeddingPatch],\n",
        "    ],\n",
        "    ensemble_method: Optional[\n",
        "        patch_embedding_ensemble_methods.PatchEnsembleMethod\n",
        "    ] = None,\n",
        ") -\u003e Iterator[patch_embedding_types.EmbeddingResult]:\n",
        "```\n",
        "\n",
        "Get patch embeddings function accepts the following parameters:\n",
        "\n",
        "- \u003cu\u003eendpoint\u003c/u\u003e: Is the abstraction interface through which EZ-WSI communicates with the various embedding model VertexAI endpoints and or local execution. See [endpoints](endpoints) for more information.\n",
        "\n",
        "- \u003cu\u003epatches\u003c/u\u003e: Either an iterator or a sequence of patches. Patches should be clustered in the input iterator/sequence such that patches from the same data source are listed sequentially in the iterator or sequence input.\n",
        "\n",
        "- \u003cu\u003eensemble_method\u003c/u\u003e: Ensemble methods are optional and enable EZ-WSI to generate embeddings for patches which exceed the embedding dimensions of the endpoint. If not provided, input patches must match the input width and height dimensions of the endpoint. See [ensemble methods](ensemble_method) for more information.\n",
        "\n",
        "***Returns:***\n",
        "\n",
        "\u003cu\u003epatch_embedding_types.EmbeddingResult\u003c/u\u003e\n",
        "\n",
        "EmbeddingResult is a common type returned by all batch methods. Embedding result is a data class which encapsulates the patch which was the source for the embedding and the produced embedding.\n",
        "\n",
        "```\n",
        "@dataclasses.dataclass(frozen=True)\n",
        "class EmbeddingResult:\n",
        "  \"\"\"Embedding result for a patch.\"\"\"\n",
        "  patch: EmbeddingPatch\n",
        "  embedding: np.ndarray\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XCiAmlWqpZO"
      },
      "source": [
        "## Generate_patch_embeddings Embedding Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa0WeAAKoiaB"
      },
      "source": [
        "### Example: Generating Patches Embeddings in Batch from WSI DICOM Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR9dI6ScaUPr"
      },
      "outputs": [],
      "source": [
        "from typing import Iterator\n",
        "\n",
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import dicom_web_interface\n",
        "from ez_wsi_dicomweb import dicom_slide\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import ez_wsi_dicomweb.ml_toolkit.dicom_path as dicom_path\n",
        "\n",
        "# Defines DICOM image stored within a Google DICOM store.\n",
        "DATASET_PROJECT_ID = 'hai-cd3-foundations'\n",
        "DATASET_LOCATION = 'us-west1'\n",
        "DATASET_ID = 'pathology'\n",
        "STORE_ID  = 'camelyon'\n",
        "STUDY_INSTANCE_UID  = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461'\n",
        "SERIES_INSTANCE_UID = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463'\n",
        "\n",
        "\n",
        "def patch_generator(ds: dicom_slide.DicomSlide, level: dicom_slide.Level, x: int, y: int, step: int, num_patches: int) -\u003e Iterator[dicom_slide.DicomPatch]:\n",
        "  \"\"\"Generates patches sequential patches the a pyramid level of a dicom slide.\"\"\"\n",
        "  for _ in range(num_patches):\n",
        "    yield ds.get_patch(level, x, y, 224, 224)\n",
        "    x += step\n",
        "    if x+step \u003e= level.width:\n",
        "      x = 0\n",
        "      y += step\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging.\n",
        "series_path = dicom_path.FromString(f'https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}')\n",
        "\n",
        "# Crediental factory that provides EZ-WSI with credentials to access DICOM imaging metadata.\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide, retrieves slide metadata but not slide imaging.\n",
        "ds = dicom_slide.DicomSlide(path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf))\n",
        "\n",
        "# The generator, generates 500 patches sampled across the a single pyramid.\n",
        "# Note, the generator could return patches sampled across multiple pyramid\n",
        "# layers or images, the only requirement is patches from the same source image\n",
        "# or pyramid layer are clustered.\n",
        "patches = patch_generator(ds, ds.native_level, 43000, 10000, 224, 500)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a the patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embeddings = patch_embedding.generate_patch_embeddings(endpoint, patches)\n",
        "\n",
        "# Convert the embedding generator into a list of values.\n",
        "embeddings = list(embeddings)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f'Embeddings returned: {len(embeddings)}')\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print('First two embeddings results')\n",
        "for result in embeddings[:2]:\n",
        "  # render the source embedding patch\n",
        "  render_patch(result.patch)\n",
        "\n",
        "  # print the location and dimensions of the patch\n",
        "  print(f'Patch Location x: {result.patch.x} y: {result.patch.y} width: {result.patch.width} height: {result.patch.height}')\n",
        "\n",
        "  # print the first 12 values of the returned embedding\n",
        "  print('First 12 values of patch image embedding.')\n",
        "  print(result.embedding[:12])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBfM7HHR68Nk"
      },
      "source": [
        "### Example: Generating Patches Embeddings in Batch from a Google Cloud Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVQxdpT0o_OY"
      },
      "outputs": [],
      "source": [
        "from typing import Iterator\n",
        "\n",
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "\n",
        "def patch_generator(image: gcs_image.GcsImage, x: int, y: int, step: int, num_patches: int) -\u003e Iterator[gcs_image.GcsPatch]:\n",
        "  \"\"\"Generates patches sequential patches the a pyramid level of a dicom slide.\"\"\"\n",
        "  for _ in range(num_patches):\n",
        "    yield image.get_patch(x, y, 224, 224)\n",
        "    x += step\n",
        "    if x+224 \u003e= image.width:\n",
        "      x = 0\n",
        "      y += step\n",
        "\n",
        "\n",
        "# Create a reference to an image stored on Google Cloud Storage\n",
        "# By default authenticates with default credientals.\n",
        "image = gcs_image.GcsImage('gs://healthai-us/pathology/example_large_patch.jpeg',\n",
        "                           credential_factory=credential_factory.NoAuthCredentialsFactory())\n",
        "\n",
        "# The generator, generates 500 patches sampled across the GCS image.\n",
        "# The image is relatively small so were generating embeddings for overlapping\n",
        "# patches, stepping the patches 10 pixels at a time.\n",
        "patches = patch_generator(image, 0, 0, 10, 500)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a the patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embeddings = patch_embedding.generate_patch_embeddings(endpoint, patches)\n",
        "\n",
        "# Convert the embedding generator into a list of values.\n",
        "embeddings = list(embeddings)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f'Embeddings returned: {len(embeddings)}')\n",
        "\n",
        "# Display results for two embeddings returned\n",
        "print('Embeddings results')\n",
        "for result in (embeddings[0], embeddings[20]):\n",
        "  # render the source embedding patch\n",
        "  render_patch(result.patch)\n",
        "\n",
        "  # print the location and dimensions of the patch\n",
        "  print(f'Patch Location x: {result.patch.x} y: {result.patch.y} width: {result.patch.width} height: {result.patch.height}')\n",
        "\n",
        "  # print the first 12 values of the returned embedding\n",
        "  print('First 12 values of patch image embedding.')\n",
        "  print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbqu0J5ssqyv"
      },
      "source": [
        "### Example: Generating Embeddings In Batch From Local File and in Memory Data Sources\n",
        "\n",
        "The performance gains from batch processing in memory requests to cloud embedding endpoints are lower due to inefficiencies associated with transferring large amounts of data from the client to the cloud endpoints. Performance is highly dependent upon the network bandwidth between the machine running EZ-WSI and the embedding Endpoint. To provide reasonable response times the number of embeddings retrieved in batch for the in memory test has been reduced by a factor of 10 from 500 to 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbTC6Xvrshw2"
      },
      "outputs": [],
      "source": [
        "from typing import Iterator\n",
        "\n",
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import local_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def patch_generator(image: local_image.LocalImage, x: int, y: int, step: int, num_patches: int) -\u003e Iterator[gcs_image.GcsPatch]:\n",
        "  \"\"\"Generates patches sequential patches the a pyramid level of a dicom slide.\"\"\"\n",
        "  for _ in range(num_patches):\n",
        "    yield image.get_patch(x, y, 224, 224)\n",
        "    x += step\n",
        "    if x+224 \u003e= image.width:\n",
        "      x = 0\n",
        "      y += step\n",
        "\n",
        "\n",
        "# Create a in memory uncompressed image filled with random noise.\n",
        "memory = np.random.randint(0, high=255, size=(224*50, 224, 3), dtype=np.uint8)\n",
        "\n",
        "# Construct an image from the in memory patch\n",
        "image = local_image.LocalImage(memory)\n",
        "\n",
        "# The generator, generates 50 patches sampled across the GCS image.\n",
        "# The image is relatively small so were generating embeddings for overlapping\n",
        "# patches, stepping the patches 10 pixels at a time.\n",
        "patches = patch_generator(image, 0, 0, 224, 50)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a the patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embeddings = patch_embedding.generate_patch_embeddings(endpoint, patches)\n",
        "\n",
        "# Convert the embedding generator into a list of values.\n",
        "embeddings = list(embeddings)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f'Embeddings returned: {len(embeddings)}')\n",
        "\n",
        "# Display results for two embeddings returned\n",
        "print('Embeddings results')\n",
        "for result in (embeddings[0], embeddings[20]):\n",
        "  # render the source embedding patch\n",
        "  render_patch(result.patch, 'Random Colors Expected')\n",
        "\n",
        "  # print the location and dimensions of the patch\n",
        "  print(f'Patch Location x: {result.patch.x} y: {result.patch.y} width: {result.patch.width} height: {result.patch.height}')\n",
        "\n",
        "  # print the first 12 values of the returned embedding\n",
        "  print('First 12 values of patch image embedding.')\n",
        "  print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UG8-q-omEuws"
      },
      "source": [
        "## PatchEmbeddingSequence Class\n",
        "\n",
        "Patch embedding sequences is a Python class that provides enhanced support for generating patch embeddings from sequences of patches, e.g., Lists or Tuples. The PatchEmbeddingSequence enables high performance iterative access and random access to patch embeddings contained within the sequence.\n",
        "\n",
        "\n",
        "```\n",
        "class PatchEmbeddingSequence(\n",
        "    collections.abc.Sequence[patch_embedding_types.EmbeddingResult]\n",
        "):\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      endpoint: patch_embedding_endpoints.AbstractPatchEmbeddingEndpoint,\n",
        "      patches: Sequence[patch_embedding_types.EmbeddingPatch],\n",
        "      ensemble_method: Optional[\n",
        "          patch_embedding_ensemble_methods.PatchEnsembleMethod\n",
        "      ] = None,\n",
        "  ):\n",
        "  \"\"\"Constructor for PatchEmbeddingSequence.\n",
        "  \n",
        "  Args:\n",
        "    endpoint: Is the an abstraction interface through which EZ-WSI communicates\n",
        "    with the various embedding model VertexAI endpoints and or local execution.\n",
        "\n",
        "    patches: A sequence of patches. Patches should be clustered in the input\n",
        "    sequence such that patch from the same data source are fall sequentially in\n",
        "    the sequence.\n",
        "\n",
        "    ensemble_method: Ensemble methods are optional and enable EZ-WSI to\n",
        "    generate embeddings for patches which exceed the embedding dimensions of\n",
        "    the endpoint. If not provided, input patches must match the input width and\n",
        "    height dimensions of the endpoint.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __eq__(self, value: Any) -\u003e bool:\n",
        "    # Tests if two patch embedding sequences are composed of the same patches\n",
        "  \n",
        "  def __contains__(self, value: Any) -\u003e bool:\n",
        "    # Tests if a patch is in the Patch Embedding Sequence.\n",
        "\n",
        "  def __getitem__(self, index: Union[int, slice]):\n",
        "    # Indexed based access to embedding results.\n",
        "    # Functionally equivalent to calling get_patch_embedding if called with int.\n",
        "    # Functionally equivalent to calling generate_patch_embeddings if called\n",
        "    # with a slice.\n",
        "\n",
        "  def get_patch(self, index: int) -\u003e patch_embedding_types,EmbeddingPatch:\n",
        "    # Index based access to the source patch for an embedding.\n",
        "\n",
        "  def get_embedding(self, index: int) -\u003e np.ndarray:\n",
        "    # Index based access to patch embedding results.\n",
        "\n",
        "  def __iter__(self) -\u003e Iterator[patch_embedding_types.EmbeddingResult]:\n",
        "    # High performance batch access to embendding results for all patches\n",
        "    # in the sequence.\n",
        "    # Functionally equivalent to calling generate_patch_embeddings.\n",
        "\n",
        "  def __len__(self) -\u003e int:\n",
        "    # Returns number of input patches in sequence.\n",
        "    # Number of patches in sequence == number of embedding results that will be # returned.\n",
        "```\n",
        "\n",
        "**Performance-Tip:**\n",
        "\n",
        "If embeddings are going to be requested for most-to-all patches in a PatchEmbedding sequence then patches then patches should be accessed using the PatchEmbeddingSequence iterator. e.g. or using an indexed slice,\n",
        "\n",
        "- \u003cu\u003eRecommended\u003c/u\u003e\u003cp\u003eAccess all sequence embedding using iterator or access a subset of sequence embeddings using index slice.\u003c/p\u003e\n",
        "\n",
        "```\n",
        "# Accessing all embeddings\n",
        "seq = patch_embedding.PatchEmbeddingSequence(list_of_patches)\n",
        "for patch_embedding_result in seq:\n",
        "  print(patch_embedding_result.embedding)\n",
        "\n",
        "# Accessing embeddings for patches at indexs: 0, 2, 4, 6, and 8.\n",
        "seq = patch_embedding.PatchEmbeddingSequence(list_of_patches)\n",
        "for patch_embedding_result in seq[:10:2]:\n",
        "  print(patch_embedding_result.embedding)\n",
        "```\n",
        "\n",
        "- \u003cu\u003eNot Recommended\u003c/u\u003e\u003cp\u003e\n",
        "Repeated iterative access to index accessor.\u003c/p\u003e\n",
        "\n",
        "```\n",
        "seq = index .PatchEmbeddingSequence(list_of_patches)\n",
        "for index in range(len(seq)):\n",
        "  patch_embedding_result = seq[index]\n",
        "  print(patch_embedding_result.embedding)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpNQvY8v6fiE"
      },
      "source": [
        "### Example: Generating Patches Embeddings in Batch from WSI DICOM Image using PatchEmbeddingSequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b00pc-1nFS55"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "\n",
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import dicom_web_interface\n",
        "from ez_wsi_dicomweb import dicom_slide\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import ez_wsi_dicomweb.ml_toolkit.dicom_path as dicom_path\n",
        "\n",
        "# Defines DICOM image stored within a Google DICOM store.\n",
        "DATASET_PROJECT_ID = 'hai-cd3-foundations'\n",
        "DATASET_LOCATION = 'us-west1'\n",
        "DATASET_ID = 'pathology'\n",
        "STORE_ID  = 'camelyon'\n",
        "STUDY_INSTANCE_UID  = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461'\n",
        "SERIES_INSTANCE_UID = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463'\n",
        "\n",
        "\n",
        "def patch_sequence(ds: dicom_slide.DicomSlide, level: dicom_slide.Level, x: int, y: int, step: int, num_patches: int) -\u003e Sequence[dicom_slide.DicomPatch]:\n",
        "  \"\"\"Generates patches sequential patches the a pyramid level of a dicom slide.\"\"\"\n",
        "  patches = []\n",
        "  for _ in range(num_patches):\n",
        "    patches.append(ds.get_patch(level, x, y, 224, 224))\n",
        "    x += step\n",
        "    if x+step \u003e= level.width:\n",
        "      x = 0\n",
        "      y += step\n",
        "  return patches\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging.\n",
        "series_path = dicom_path.FromString(f'https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}')\n",
        "\n",
        "# Crediental factory that provides EZ-WSI with credentials to access DICOM imaging metadata.\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide, retrieves slide metadata but not slide imaging.\n",
        "ds = dicom_slide.DicomSlide(path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf))\n",
        "\n",
        "# The generator, generates 500 patches sampled across the a single pyramid.\n",
        "# Note, the generator could return patches sampled across multiple pyramid\n",
        "# layers or images, the only requirement is patches from the same source image\n",
        "# or pyramid layer are clustered.\n",
        "patches = patch_sequence(ds, ds.native_level, 43000, 10000, 224, 500)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a the patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embeddings = patch_embedding.PatchEmbeddingSequence(endpoint, patches)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f'Embeddings returned: {len(embeddings)}')\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print('First two embeddings results')\n",
        "for result in embeddings[:2]:\n",
        "  # render the source embedding patch\n",
        "  render_patch(result.patch)\n",
        "\n",
        "  # print the location and dimensions of the patch\n",
        "  print(f'Patch Location x: {result.patch.x} y: {result.patch.y} width: {result.patch.width} height: {result.patch.height}')\n",
        "\n",
        "  # print the first 12 values of the returned embedding\n",
        "  print('First 12 values of patch image embedding.')\n",
        "  print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKV_aDXTocdM"
      },
      "source": [
        "### Example: Generating Patches Embeddings in Batch from a Google Cloud Storage Image UsingPatchEmbeddingSequence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgA47PaN7p1g"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "\n",
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "\n",
        "def patch_sequence(image: gcs_image.GcsImage, x: int, y: int, step: int, num_patches: int) -\u003e Sequence[gcs_image.GcsPatch]:\n",
        "  \"\"\"Generates patches sequential patches the a pyramid level of a dicom slide.\"\"\"\n",
        "  patches = []\n",
        "  for _ in range(num_patches):\n",
        "    patches.append(image.get_patch(x, y, 224, 224))\n",
        "    x += step\n",
        "    if x+224 \u003e= image.width:\n",
        "      x = 0\n",
        "      y += step\n",
        "  return patches\n",
        "\n",
        "\n",
        "# Create a reference to an image stored on Google Cloud Storage\n",
        "# By default authenticates with default credientals.\n",
        "image = gcs_image.GcsImage('gs://healthai-us/pathology/example_large_patch.jpeg',\n",
        "                           credential_factory=credential_factory.NoAuthCredentialsFactory())\n",
        "\n",
        "# The generator, generates 500 patches sampled across the a single pyramid.\n",
        "# Note, the generator could return patches sampled across multiple pyramid\n",
        "# layers or images, the only requirement is patches from the same source image\n",
        "# or pyramid layer are clustered.\n",
        "patches = patch_sequence(image, 0, 0, 10, 500)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a the patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embeddings = patch_embedding.PatchEmbeddingSequence(endpoint, patches)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f'Embeddings returned: {len(embeddings)}')\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print('First two embeddings results')\n",
        "for result in embeddings[:2]:\n",
        "  # render the source embedding patch\n",
        "  render_patch(result.patch)\n",
        "\n",
        "  # print the location and dimensions of the patch\n",
        "  print(f'Patch Location x: {result.patch.x} y: {result.patch.y} width: {result.patch.width} height: {result.patch.height}')\n",
        "\n",
        "  # print the first 12 values of the returned embedding\n",
        "  print('First 12 values of patch image embedding.')\n",
        "  print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YtEDJ1L8_KL"
      },
      "source": [
        "### Example: Generating Embeddings In Batch From In Local/Memory Data Sources using PatchEmbeddingSequence\n",
        "\n",
        "The performance gains from batch processing in memory requests to cloud embedding endpoints are lower due to inefficencys associated with transfering large amounts of data from the client to the cloud endpoints. Performance is highly dependent upon the network bandwith between the machine running EZ-WSI and the embedding Endpoint. To provided resonable colab response times the number of embeddings retrieved in batch for the in memory test has been reduced by a factor of 10 from 500 to 50."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzVMvyyC9ju7"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "\n",
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import local_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def patch_sequence(image: gcs_image.GcsImage, x: int, y: int, step: int, num_patches: int) -\u003e Sequence[gcs_image.GcsPatch]:\n",
        "  \"\"\"Generates patches sequential patches the a pyramid level of a dicom slide.\"\"\"\n",
        "  patches = []\n",
        "  for _ in range(num_patches):\n",
        "    patches.append(image.get_patch(x, y, 224, 224))\n",
        "    x += step\n",
        "    if x+224 \u003e= image.width:\n",
        "      x = 0\n",
        "      y += step\n",
        "  return patches\n",
        "\n",
        "\n",
        "# Create a in memory uncompressed image filled with random noise.\n",
        "memory = np.random.randint(0, high=255, size=(224*50, 224, 3), dtype=np.uint8)\n",
        "\n",
        "# Construct an image from the in memory patch\n",
        "image = local_image.LocalImage(memory)\n",
        "\n",
        "# The generator, generates 50 patches sampled across the GCS image.\n",
        "# The image is relatively small so were generating embeddings for overlapping\n",
        "# patches, stepping the patches 10 pixels at a time.\n",
        "patches = patch_sequence(image, 0, 0, 224, 50)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes a the patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embeddings = patch_embedding.PatchEmbeddingSequence(endpoint, patches)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f'Embeddings returned: {len(embeddings)}')\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print('First two embeddings results')\n",
        "for result in embeddings[:2]:\n",
        "  # render the source embedding patch\n",
        "  render_patch(result.patch)\n",
        "\n",
        "  # print the location and dimensions of the patch\n",
        "  print(f'Patch Location x: {result.patch.x} y: {result.patch.y} width: {result.patch.width} height: {result.patch.height}')\n",
        "\n",
        "  # print the first 12 values of the returned embedding\n",
        "  print('First 12 values of patch image embedding.')\n",
        "  print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3MAEDOdrYUT"
      },
      "source": [
        "# Higher Level Embedding Generation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjOyfqKZ_CkM"
      },
      "source": [
        "## Selectively Generating Embeddings From Sub-Regions of a Whole Image\n",
        "\n",
        "EZ-WSI contains high level patch generation functions to selectively generate patches from regions of interest (e.g., areas containing tissue) within a DICOM pyramid layer, Google Cloud Storage Image, or from a local data source."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhmzIZqhrqGZ"
      },
      "source": [
        "### Selectively Generating Embeddings from a DICOM WSI Pyramid Layer or DICOM Image\n",
        "\n",
        "The function get_dicom_image_embeddings returns a PatchEmbeddingSequence of embeddings that are selectively sampled across a DICOM WSI pyramid layer or DICOM Image. If a mask is not provided and mask generation parameters are not defined then a default mask is generated using the DicomPatchGenerator defaults.\n",
        "\n",
        "```\n",
        "def get_dicom_image_embeddings(\n",
        "    endpoint: patch_embedding_endpoints.AbstractPatchEmbeddingEndpoint,\n",
        "    slide: dicom_slide.DicomSlide,\n",
        "    ps: Union[\n",
        "        slide_level_map.Level,\n",
        "        slide_level_map.ResizedLevel,\n",
        "        pixel_spacing.PixelSpacing,\n",
        "    ],\n",
        "    patch_size: Optional[int] = None,\n",
        "    mask: Optional[np.ndarray] = None,\n",
        "    stride_size: Optional[int] = None,\n",
        "    min_luminance: Optional[float] = None,\n",
        "    max_luminance: Optional[float] = None,\n",
        "    mask_level: Union[\n",
        "        slide_level_map.Level,\n",
        "        slide_level_map.ResizedLevel,\n",
        "        pixel_spacing.PixelSpacing,\n",
        "        None,\n",
        "    ] = None,\n",
        "    ensemble_method: Optional[\n",
        "        patch_embedding_ensemble_methods.PatchEnsembleMethod\n",
        "    ] = None,\n",
        ") -\u003e PatchEmbeddingSequence:\n",
        "```\n",
        "\n",
        "The function takes the parameters listed:\n",
        "\n",
        "- \u003cu\u003eendpoint\u003c/u\u003e: Is the abstraction interface through which EZ-WSI communicates with the various embedding model VertexAI endpoints and or local execution. See [endpoints](endpoints) for more information.\n",
        "\n",
        "- \u003cu\u003eslide\u003c/u\u003e: The DICOM Slide that will be used to generate patch embeddings.\n",
        "\n",
        "- \u003cu\u003eps\u003c/u\u003e: DICOM image level (wsi pyramid level or DICOM untiled DICOM image) that is the source for patch embeddings. If imaging is being generated from a WSI pyramid then ps can define the pixel spacing of the desired image level.\n",
        "\n",
        "- \u003cu\u003epatch_size\u003c/u\u003e: Source embedding patches are square. Patch size defines the length in pixels of an edge of the patch. If undefined defaults to patch dimensions of the endpoint.\n",
        "\n",
        "- \u003cu\u003emask\u003c/u\u003e: User defined mask (numpy array, dtype=np.bool_). That defines which regions of the image contain regions of interest (e.g. tissue).  If not defined, masks will be generated using mask generation parameters.\n",
        "\n",
        "- \u003cu\u003estride_size\u003c/u\u003e: The spacing between the upper left coordinate of the patches. Patches sampled with stride \u003c patch_size will overlap. If undefined defaults to patch_size.\n",
        "\n",
        "- \u003cu\u003emin_luminance\u003c/u\u003e: If a tissue mask is not defined. Defines the minimum luminance value (range 0 - 1.0), for pixels to be considered of interest (e.g.,  tissue). If undefined defaults to (1.0 / 255.0), not applicable if generating from user defined mask.\n",
        "\n",
        "- \u003cu\u003emax_luminance\u003c/u\u003e: If a tissue mask is not defined. Defines the maximum luminance value (range 0 - 1.0), for pixels to be considered regions of interest (e.g., tissue). If undefined defaults to (204.0 / 255.0), not applicable if generating from user defined mask.\n",
        "\n",
        "- \u003cu\u003emask_level\u003c/u\u003e: Defines the image level within the DICOM WSI pyramid layer that will be thresholded and used to generate a sampling mask. All imaging from level will be retrieved to generate sampling mask. It is highly recommended that relatively low magnification, high pixel spacing, levels  be used to generate the mask. The parameter is not applicable if a user defined mask is provided or if sampling from a non-tiled DICOM image. If undefined and applicable, this parameter will default to retrieve imaging that is ~1.25X.\n",
        "\n",
        "- \u003cu\u003eEnsemble_method\u003c/u\u003e: Ensemble methods are optional and enable EZ-WSI to generate embeddings for patches which exceed the embedding dimensions of the endpoint. If not provided, input patches must match the input width and height dimensions of the endpoint. See [ensemble methods](ensemble_method) for more information.\n",
        "\n",
        "**Returns:**\n",
        "\n",
        "  A PatchEmbeddingSequence that will generate and return embeddings sampled across the DICOM imaging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSnYCOPy-2cX"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import dicom_web_interface\n",
        "from ez_wsi_dicomweb import dicom_slide\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import ez_wsi_dicomweb.ml_toolkit.dicom_path as dicom_path\n",
        "\n",
        "# Defines DICOM image stored within a Google DICOM store.\n",
        "DATASET_PROJECT_ID = 'hai-cd3-foundations'\n",
        "DATASET_LOCATION = 'us-west1'\n",
        "DATASET_ID = 'pathology'\n",
        "STORE_ID  = 'camelyon'\n",
        "STUDY_INSTANCE_UID  = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461'\n",
        "SERIES_INSTANCE_UID = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463'\n",
        "\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging.\n",
        "series_path = dicom_path.FromString(f'https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}')\n",
        "\n",
        "# Crediental factory that provides EZ-WSI with credentials to access DICOM imaging metadata.\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide, retrieves slide metadata but not slide imaging.\n",
        "ds = dicom_slide.DicomSlide(path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf))\n",
        "\n",
        "# Optional but highly recommended, enables DS to retrieve patch imaging more\n",
        "# efficiently when generating the tissue mask.\n",
        "ds.init_slide_frame_cache()\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "embeddings = patch_embedding.get_dicom_image_embeddings(endpoint, ds, ds.native_level)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f'Embeddings returned: {len(embeddings)}')\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print('First two embeddings results')\n",
        "for result in embeddings[:2]:\n",
        "  # render the source embedding patch\n",
        "  render_patch(result.patch)\n",
        "\n",
        "  # print the location and dimensions of the patch\n",
        "  print(f'Patch Location x: {result.patch.x} y: {result.patch.y} width: {result.patch.width} height: {result.patch.height}')\n",
        "\n",
        "  # print the first 12 values of the returned embedding\n",
        "  print('First 12 values of patch image embedding.')\n",
        "  print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I89cRPHJWWoT"
      },
      "source": [
        "###Selectively Generating Embeddings from a image stored in Google Cloud Storage or from Local File or in Memory Data.\n",
        "\n",
        "The function get_gcs_image_embeddings returns a PatchEmbeddingSequence of embeddings that are selectively sampled from an image stored on Google Cloud Storage or from an image loaded in memory. If a mask is not provided defined and mask generation parameters are not defined then a default mask is generated using the GcsImagePatchGenerator defaults.\n",
        "\n",
        "```\n",
        "def get_dicom_image_embeddings(\n",
        "    endpoint: patch_embedding_endpoints.AbstractPatchEmbeddingEndpoint,\n",
        "    image: Union[gcs_image.GcsImage, local_image.LocalImage],\n",
        "    patch_size: Optional[int] = None,\n",
        "    mask: Optional[np.ndarray] = None,\n",
        "    stride_size: Optional[int] = None,\n",
        "    min_luminance: Optional[float] = None,\n",
        "    max_luminance: Optional[float] = None,\n",
        "    ensemble_method: Optional[\n",
        "        patch_embedding_ensemble_methods.PatchEnsembleMethod\n",
        "    ] = None,\n",
        ") -\u003e PatchEmbeddingSequence:\n",
        "```\n",
        "\n",
        "The function takes the parameters listed:\n",
        "\n",
        "- \u003cu\u003eendpoint\u003c/u\u003e: Is the abstraction interface through which EZ-WSI communicates with the various embedding model VertexAI endpoints and or local execution. See [endpoints](endpoints) for more information.\n",
        "\n",
        "- \u003cu\u003eimage\u003c/u\u003e: The source image that patches and embeddings will be generated from. An image can be an image stored on Google Cloud Store, or locally.\n",
        "\n",
        "- \u003cu\u003epatch_size\u003c/u\u003e: Source embedding patches are square. Patch size defines the length in pixels of an edge of the patch. If undefined defaults to patch dimensions of the endpoint.\n",
        "\n",
        "- \u003cu\u003emask\u003c/u\u003e: User defined mask (numpy array, dtype=np.bool_). That will define which regions of the image contain regions of interest (e.g. tissue). If not defined, masks will be generated using tissue mask generation parameters.\n",
        "\n",
        "- \u003cu\u003estride_size\u003c/u\u003e: The spacing between the upper left coordinate of the patches. Patches sampled with stride \u003c patch_size will overlap. If undefined defaults to patch_size.\n",
        "\n",
        "- \u003cu\u003emin_luminance\u003c/u\u003e: If a tissue mask is not defined. Defines the minimum luminance value (range 0 - 1.0), for pixels to be considered of interest (e.g., tissue). If undefined defaults to (1.0 / 255.0), not applicable if generated from a user defined tissue mask.\n",
        "\n",
        "- \u003cu\u003emax_luminance\u003c/u\u003e: If a tissue mask is not defined. Defines the maximum luminance value (range 0 - 1.0), for pixels to be considered regions of interest (e.g., tissue). If undefined defaults to (204.0 / 255.0), not applicable if generated from a user defined tissue mask.\n",
        "\n",
        "- \u003cu\u003eEnsemble_method\u003c/u\u003e: Ensemble methods are optional and enable EZ-WSI to generate embeddings for patches which exceed the embedding dimensions of the endpoint. If not provided, input patches must match the input width and height dimensions of the endpoint. See [ensemble methods](ensemble_method) for more information.\n",
        "\n",
        "**Returns:**\n",
        "\n",
        "A PatchEmbeddingSequence that will generate and return embeddings sampled across the DICOM imaging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wskE8SKgCxF"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import dicom_web_interface\n",
        "from ez_wsi_dicomweb import dicom_slide\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "from ez_wsi_dicomweb import patch_generator\n",
        "import ez_wsi_dicomweb.ml_toolkit.dicom_path as dicom_path\n",
        "import numpy as np\n",
        "\n",
        "# Defines DICOM image stored within a Google DICOM store.\n",
        "DATASET_PROJECT_ID = 'hai-cd3-foundations'\n",
        "DATASET_LOCATION = 'us-west1'\n",
        "DATASET_ID = 'pathology'\n",
        "STORE_ID  = 'camelyon'\n",
        "STUDY_INSTANCE_UID  = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461'\n",
        "SERIES_INSTANCE_UID = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463'\n",
        "\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging.\n",
        "series_path = dicom_path.FromString(f'https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}')\n",
        "\n",
        "# Crediental factory that provides EZ-WSI with credentials to access DICOM imaging metadata.\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide, retrieves slide metadata but not slide imaging.\n",
        "ds = dicom_slide.DicomSlide(path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf))\n",
        "\n",
        "# Optional but highly recommended, enables DS to retrieve patch imaging more\n",
        "# efficiently when generating the tissue mask.\n",
        "ds.init_slide_frame_cache()\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "mask = np.zeros((ds.native_level.height//10, ds.native_level.width//10), dtype=np.bool_)\n",
        "mask[int(mask.shape[0]/ 2), int(mask.shape[0]/ 2)] = True\n",
        "embeddings = patch_embedding.get_dicom_image_embeddings(endpoint, ds, ds.native_level, mask=mask)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f'Embeddings returned: {len(embeddings)}')\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "for result in embeddings[:2]:\n",
        "  # render the source embedding patch\n",
        "  render_patch(result.patch)\n",
        "\n",
        "  # print the location and dimensions of the patch\n",
        "  print(f'Patch Location x: {result.patch.x} y: {result.patch.y} width: {result.patch.width} height: {result.patch.height}')\n",
        "\n",
        "  # print the first 12 values of the returned embedding\n",
        "  print('First 12 values of patch image embedding.')\n",
        "  print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cBb_QOKp5bD"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "\n",
        "\n",
        "# Create a reference to an image stored on Google Cloud Storage\n",
        "# By default authenticates with default credientals.\n",
        "image = gcs_image.GcsImage('gs://healthai-us/pathology/example_large_patch.jpeg',\n",
        "                           credential_factory=credential_factory.NoAuthCredentialsFactory())\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "embeddings = patch_embedding.get_gcs_image_embeddings(endpoint, image)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f'Embeddings returned: {len(embeddings)}')\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print('First two embeddings results')\n",
        "for result in embeddings[:2]:\n",
        "  # render the source embedding patch\n",
        "  render_patch(result.patch)\n",
        "\n",
        "  # print the location and dimensions of the patch\n",
        "  print(f'Patch Location x: {result.patch.x} y: {result.patch.y} width: {result.patch.width} height: {result.patch.height}')\n",
        "\n",
        "  # print the first 12 values of the returned embedding\n",
        "  print('First 12 values of patch image embedding.')\n",
        "  print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgPdjFQ4eJjU"
      },
      "source": [
        "### Example: Selectively Generating Embeddings from a Local File or in Memory Data Source\n",
        "\n",
        "The performance gains from batch processing in memory requests to cloud embedding endpoints are lower due to inefficiencies associated with transferring large amounts of data from the client to the cloud endpoints. Performance is highly dependent upon the network bandwidth between the machine running EZ-WSI and the embedding Endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khfyG2yodmwX"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import local_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Create a in memory uncompressed image filled with random noise.\n",
        "memory = np.random.randint(0, high=255, size=(224*50, 224, 3), dtype=np.uint8)\n",
        "\n",
        "# Construct an image from the in memory patch\n",
        "image = local_image.LocalImage(memory)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "embeddings = patch_embedding.get_gcs_image_embeddings(endpoint, image)\n",
        "\n",
        "# Display total number of embeddings generated\n",
        "print(f'Embeddings returned: {len(embeddings)}')\n",
        "\n",
        "# Display results for first two embeddings returned\n",
        "print('First two embeddings results')\n",
        "for result in embeddings[:2]:\n",
        "  # render the source embedding patch\n",
        "  render_patch(result.patch)\n",
        "\n",
        "  # print the location and dimensions of the patch\n",
        "  print(f'Patch Location x: {result.patch.x} y: {result.patch.y} width: {result.patch.width} height: {result.patch.height}')\n",
        "\n",
        "  # print the first 12 values of the returned embedding\n",
        "  print('First 12 values of patch image embedding.')\n",
        "  print(result.embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxsMBlKMfzpA"
      },
      "source": [
        "### Reducing Embedding Result Sequences or Iterators of Embedding Results to a Single Embedding\n",
        "The high level functions, get_dicom_image_embeddings and get_gcs_image_embeddings, that selectively generate embeddings for a DICOM image, Google Cloud Storage image, or from a local data source can also be reduced using a utility function, mean_patch_embedding, that is included in the the patch_embedding_ensemble_methods module. This function takes an iterator or sequence of embedding results, and returns the mean embedding result of all the embeddings in the sequence.\n",
        "\n",
        "\n",
        "```\n",
        "def mean_patch_embedding(\n",
        "    embeddings: Union[\n",
        "        Iterator[patch_embedding_types.EmbeddingResult],\n",
        "        Sequence[patch_embedding_types.EmbeddingResult],\n",
        "    ],\n",
        ") -\u003e np.ndarray:\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqCULYL1h_gm"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "from ez_wsi_dicomweb import patch_embedding_ensemble_methods\n",
        "\n",
        "\n",
        "# Create a reference to an image stored on Google Cloud Storage\n",
        "# By default authenticates with default credientals.\n",
        "image = gcs_image.GcsImage('gs://healthai-us/pathology/example_large_patch.jpeg',\n",
        "                           credential_factory=credential_factory.NoAuthCredentialsFactory())\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Selectively generates embeddings cross a GCS Image.\n",
        "embeddings = patch_embedding.get_gcs_image_embeddings(endpoint, image)\n",
        "\n",
        "print(f'Reducing {len(embeddings)} to a single embedding.')\n",
        "# Reduces the 20 embeddings returned by get_gcs_image_embeddings to a single\n",
        "# embedding.\n",
        "embedding = patch_embedding_ensemble_methods.mean_patch_embedding(embeddings)\n",
        "\n",
        "print('First 12 values of patch image embedding.')\n",
        "print(embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXnpk6tWtBkr"
      },
      "source": [
        "## Generating Embeddings for Collections of Images Stored on Google Cloud Storage or Locally.\n",
        "\n",
        "For ML training pipelines it is often necessary to generate embeddings for collections of images. EZ-WSI provides methods which enable sequences or iterators which return references to images stored on Google Cloud Storage or on locally to be easily converted into batch requests for pathology embeddings. These methods support automated image rescaling to a common dimensions and more advanced embedding ensembling to enable embedding generation from images of different sizes. Methods for selective sampling of sub-regions of the images is not supported by the provided methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5jk-h2M3-_H"
      },
      "source": [
        "### Generating Embeddings for Lists of Images stored on Google Cloud Storage\n",
        "\n",
        "The gcs_images_to_embeddings function will transform lists of references to imaging stored on Google Cloud Storage into Embeddings. The [Google Cloud Storage Python Client Library](https://pypi.org/project/google-cloud-storage/) provides high level methods which will return iterators that list data (e.g., images) stored on the service, e.g. [google.cloud.storage.Client.list_blobs](https://cloud.google.com/python/docs/reference/storage/latest/google.cloud.storage.client.Client#google_cloud_storage_client_Client_list_blobs) and [google.cloud.storage.Blucket.list_blobs](https://cloud.google.com/python/docs/reference/storage/latest/google.cloud.storage.bucket.Bucket#google_cloud_storage_bucket_Bucket_list_blobs)). The output of these methods can be directly connected to this method to return embeddings for imaging in batch. Alternatively, a sequence or iterator that contains/returns a string referencing imaging using gs style paths 'gs://bucket/image.png' can be passed as input to gcs_images_to_embeddings to define a list of images stored on Google Cloud Storage.\n",
        "\n",
        "```\n",
        "def gcs_images_to_embeddings(\n",
        "    endpoint: patch_embedding_endpoints.AbstractPatchEmbeddingEndpoint,\n",
        "    images: patch_generator.GcsImagesToPatchesInputTypes,\n",
        "    credential_factory: Optional[\n",
        "        credential_factory_module.AbstractCredentialFactory\n",
        "    ] = None,\n",
        "    image_dimensions: Optional[gcs_image.ImageDimensions] = None,\n",
        "    ensemble_method: Optional[\n",
        "        patch_embedding_ensemble_methods.PatchEnsembleMethod\n",
        "    ] = None,\n",
        ") -\u003e Iterator[patch_embedding_types.EmbeddingResult]:\n",
        "```\n",
        "\n",
        "The function takes the parameters listed:\n",
        "\n",
        "- \u003cu\u003eendpoint\u003c/u\u003e: Is the abstraction interface through which EZ-WSI communicates with the various embedding model VertexAI endpoints and or local execution. See [endpoints](endpoints) for more information.\n",
        "\n",
        "- \u003cu\u003eimages\u003c/u\u003e: A sequence or iterator of paths to images stored on Google Cloud Storage.\n",
        "\n",
        "- \u003cu\u003ecredential_factory\u003c/u\u003e: A ez-wsi credential factory that provides authentication credentials to connect to the imaging on Google Cloud Storage. If undefined will use the associated Application Default Credentials of the user / service account executing EZ-WSI.\n",
        "\n",
        "- \u003cu\u003eimage_dimensions\u003c/u\u003e: Optional dimensions that all images will be rescaled to prior to embedding generation.\n",
        "\n",
        "- \u003cu\u003eensemble_method\u003c/u\u003e: Ensemble methods are optional and enable EZ-WSI to generate embeddings for patches which exceed the embedding dimensions of the endpoint. If not provided, input patches must match the input width and height dimensions of the endpoint. See [ensemble methods](ensemble_method) for more information.\n",
        "\n",
        "**Returns:**\n",
        "\n",
        "Function returns an iterator which returns the embeddings and a reference to the source imaging that the embedding was generated from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at-9GLBQPXqZ"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import google.cloud.storage\n",
        "\n",
        "\n",
        "# Create a Python Client to Google Cloud Storage\n",
        "# Use Application Default Credentials to connect.\n",
        "cl = google.cloud.storage.Client.create_anonymous_client()\n",
        "\n",
        "# Connect to bucket using client credientals\n",
        "bucket = google.cloud.storage.bucket.Bucket(name='healthai-us', client=cl)\n",
        "\n",
        "# Create an iterator that returns all blobs stored on the bucket at gs://healthai-us/pathology/training/cancer\n",
        "images = bucket.list_blobs(prefix='pathology/training/cancer')\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Pass the iterator to gcs_images_to_embeddings to generate embeddings for all images stored at the bucket\n",
        "# Use application default credientals to access imaging.\n",
        "# Resize all imaging to 224 x 224 pixels prior to embedding generation.\n",
        "embeddings = patch_embedding.gcs_images_to_embeddings(endpoint, images, image_dimensions=gcs_image.ImageDimensions(224, 224))\n",
        "\n",
        "# iterate over the returned embedding results\n",
        "for index, result in enumerate(embeddings):\n",
        "  if index == 3:\n",
        "    break\n",
        "  # render the source embedding patch and list the uri of the\n",
        "  # source data.\n",
        "  render_patch(result.patch, result.patch.source.uri)\n",
        "\n",
        "  # print the first 12 values of the returned embedding\n",
        "  print('First 12 values of patch image embedding.')\n",
        "  print(result.embedding[:12])\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spUP36UGS3wE"
      },
      "source": [
        "### Generating Embeddings for Lists of Images stored on Locally\n",
        "\n",
        "The local_images_to_embeddings function will transform lists of in memory data or image files stored locally into embeddings.\n",
        "\n",
        "```\n",
        "def local_images_to_embeddings(\n",
        "    endpoint: patch_embedding_endpoints.AbstractPatchEmbeddingEndpoint,\n",
        "    images: patch_generator.GcsImagesToPatchesInputTypes,\n",
        "    image_dimensions: Optional[gcs_image.ImageDimensions] = None,\n",
        "    ensemble_method: Optional[\n",
        "        patch_embedding_ensemble_methods.PatchEnsembleMethod\n",
        "    ] = None,\n",
        ") -\u003e Iterator[patch_embedding_types.EmbeddingResult]:\n",
        "```\n",
        "\n",
        "The function takes the parameters listed:\n",
        "\n",
        "- \u003cu\u003eendpoint\u003c/u\u003e: Is the an abstraction interface through which EZ-WSI communicates with the various embedding model VertexAI endpoints and or local execution. See [endpoints](endpoints) for more information.\n",
        "\n",
        "- \u003cu\u003eimages\u003c/u\u003e: A sequence or iterator of paths to images stored locally or image data loaded into memory uncompressed as numpy array or compressed as bytes.\n",
        "\n",
        "- \u003cu\u003eimage_dimensions\u003c/u\u003e: Optional dimensions that all images will be rescaled to prior to embedding generation.\n",
        "\n",
        "- \u003cu\u003eensemble_method\u003c/u\u003e: Ensemble methods are optional and enable EZ-WSI to generate embeddings for patches which exceed the embedding dimensions of the endpoint. If not provided, input patches must match the input width and height dimensions of the endpoint. See [ensemble methods](ensemble_method) for more information.\n",
        "\n",
        "**Returns:**\n",
        "\n",
        "Function returns an iterator which returns the embeddings and references to the source imaging that the embedding was generated from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwmCnslcWkPu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "\n",
        "\n",
        "# Create a temporary directory in the colab to write three example images too.\n",
        "# Directory and images removed when context block is exited.\n",
        "with tempfile.TemporaryDirectory() as temp_dir:\n",
        "  # create memory hold temporary images that we are creating\n",
        "  image = np.zeros((224, 224), dtype=np.uint8)\n",
        "  # Write three images that are just a solid monochrome color\n",
        "  for color in (0, 128, 180):\n",
        "    image[...] = color\n",
        "    # write the image to the temporary directory\n",
        "    with PIL.Image.fromarray(image) as img:\n",
        "      img.save(os.path.join(temp_dir, f'image_{color}.png'))\n",
        "\n",
        "  # Colab Setup Complete\n",
        "\n",
        "  # Create a list of images that we wrote to the temporary directory\n",
        "  images = [os.path.join(temp_dir, fname) for fname in os.listdir(temp_dir)]\n",
        "\n",
        "  # Defines the endpoint that will called to generate the embedding.\n",
        "  endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "  # Request embeddings for the list iof images\n",
        "  embeddings = patch_embedding.local_images_to_embeddings(endpoint, images)\n",
        "  # iterate over the returned embedding results\n",
        "  for result in embeddings:\n",
        "    # render the source embedding patch and list the filename of the\n",
        "    # source data.\n",
        "    render_patch(result.patch, result.patch.source.filename)\n",
        "\n",
        "    # print the first 12 values of the returned embedding\n",
        "    print('First 12 values of patch image embedding.')\n",
        "    print(result.embedding[:12])\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TslzgU1qhC__"
      },
      "source": [
        "## \u003ca name=\"ensemble_method\"\u003eEmbedding Ensemble Methods\u003c/a\u003e\n",
        "The pathology embeddings REST API \u003cu\u003erequires\u003c/u\u003e that the size of a patch in an embedding request matches the endpoints input requirements. The V1 and V2 endpoints generate embeddings for 224 x 224 images, and require all input patch imaging to be 224 x 224 pixels.\n",
        "\n",
        "EZ-WSI loosens this requirement and enables \u003cu\u003eembeddings to be generated for patches of arbitrary dimensions\u003c/u\u003e. EZ-WSI accomplishes this by providing all embedding generation functions and classes with an optional PatchEnsembleMethod parameter. This parameter defines methods that: 1) which enable imaging of arbitrary size to be broken into one or more patches, and 2) reduce a collection of embeddings into a single embedding.\n",
        "\n",
        "EZ-WSI defines four patch embedding ensemble methods and an interface through which custom embedding ensemble methods can be easily integrated. The methods provided by EZ-WSI are:\n",
        "\n",
        "- \u003cb\u003eDefaultSinglePatchEnsemble\u003c/b\u003e: This is the default ensemble method that all embedding functions and classes use. This ensemble method enforces the requirement that the dimensions of input imaging match the endpoint.\n",
        "\n",
        "```\n",
        "class DefaultSinglePatchEnsemble(SinglePatchEnsemble):\n",
        "  \"\"\"Returns single embedding for patch, validates patch dim = embedding dim.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "\n",
        "```\n",
        "\n",
        "- \u003cb\u003eSinglePatchEnsemble\u003c/b\u003e: This ensemble method accepts a patch of arbitrary input dimensions and replaces them with a \u003cu\u003esingle patch embedding request\u003c/u\u003e that matches the endpoints input requirements. The position of the new newly created patch is defined in one of 5 positions relative to the source patch.\n",
        "\n",
        "\n",
        "```\n",
        "class SinglePatchEnsemblePosition(enum.Enum):\n",
        "  UPPER_LEFT = 'UPPER_LEFT'\n",
        "  UPPER_RIGHT = 'UPPER_RIGHT'\n",
        "  CENTER = 'CENTER'\n",
        "  LOWER_LEFT = 'LOWER_LEFT'\n",
        "  LOWER_RIGHT = 'LOWER_RIGHT'\n",
        "\n",
        "\n",
        "class SinglePatchEnsemble(PatchEnsembleMethod):\n",
        "  \"\"\"Returns embedding generated from a single patch.\"\"\"\n",
        "\n",
        "  def __init__(self, position: SinglePatchEnsemblePosition):\n",
        "    \"\"\"SinglePatchEnsemble Constructor.\n",
        "\n",
        "    Args:\n",
        "      position: Position of patch to generate embedding.\n",
        "\n",
        "    Raises:\n",
        "      ez_wsi_errors.SinglePatchEmbeddingEnsemblePositionError: Invalid\n",
        "        SinglePatchEnsemblePosition.\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "- \u003cb\u003eFivePatchMeanEnsemble\u003c/b\u003e: This method returns the mean embedding of five patches sampled at the upper left, upper right, center, lower left, and lower right positions.\n",
        "\n",
        "\n",
        "```\n",
        "class FivePatchMeanEnsemble(PatchEnsembleMethod):\n",
        "  \"\"\"Returns mean embedding from five patches sampled across the patch.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "```\n",
        "\n",
        "- \u003cb\u003eMeanPatchEmbeddingEnsemble\u003c/b\u003e: This ensemble method accepts a patch of arbitrary input dimensions and replaces it with multiple patch requests that are sampled across the source patches dimensions. Patch embeddings are reduced to a single embedding by computing the element wise mean of the generated embeddings.\n",
        "\n",
        "\n",
        "```\n",
        "class MeanPatchEmbeddingEnsemble(PatchEnsembleMethod):\n",
        "  \"\"\"Returns mean embedding from set of embeddings sampled across the patch.\"\"\"\n",
        "\n",
        "  def __init__(self, step_x_px: int, step_y_px: int):\n",
        "    \"\"\"MeanPatchEmbeddingEnsemble Constructor.\n",
        "\n",
        "    Args:\n",
        "      step_x_px: Step size in x direction to sample patch for embedding.\n",
        "      step_y_px: Step size in y direction to sample patch for embedding.\n",
        "\n",
        "    Raises:\n",
        "      ez_wsi_errors.SinglePatchEmbeddingEnsemblePositionError: Invalid\n",
        "        SinglePatchEnsemblePosition.\n",
        "    \"\"\"\n",
        "```\n",
        "\n",
        "** Custom Ensemble Methods **\n",
        "\n",
        "Writing custom patch embedding ensemble methods. Patch embedding ensemble methods are extensible by creating a custom class that inherits from PatchEnsembleMethod. Ensemble methods are required to implement two abstract methods that define how the ensemble method will transform an arbitrary patch embedding request into one or more requests that an endpoint can process and then how those generated embeddings will be reduced to a single embedding. The methods implemented in EZ-WSI are relatively simple. However these methods need not be limited to simple summary statistics (e.g., mean) and could conceptually be used to trigger additional complex ML that identifies the relevant regions of patch and then performs more complex/intelligent embedding reduction.\n",
        "\n",
        "```\n",
        "  @abc.abstractmethod\n",
        "  def generate_ensemble(\n",
        "      self,\n",
        "      endpoint: patch_embedding_endpoints.AbstractPatchEmbeddingEndpoint,\n",
        "      patch: patch_embedding_types.EmbeddingPatch,\n",
        "  ) -\u003e Iterator[patch_embedding_types.PatchEmbeddingSource]:\n",
        "    \"\"\"Yields iterator of patches of embedding dim to gen embedding for patch.\n",
        "\n",
        "    Args:\n",
        "      endpoint: Embedding endpoint used to generate patch embeddings.\n",
        "      patch: Input pixel region to generate an embedding.\n",
        "\n",
        "    Yields:\n",
        "      PatchEmbeddingSource that define one or more sub patches that are\n",
        "      required to generate an embedding for the patch.\n",
        "    \"\"\"\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def reduce_ensemble(\n",
        "      self,\n",
        "      patch: patch_embedding_types.EmbeddingPatch,\n",
        "      ensemble_list: _ReducedType,\n",
        "  ) -\u003e patch_embedding_types.EmbeddingResult:\n",
        "    \"\"\"Returns single embedding result from ensemble of patch embeddings.\n",
        "\n",
        "    Args:\n",
        "      patch: Input pixel region embedding was generated from\n",
        "      ensemble_list: List of embedding results generated within patch\n",
        "\n",
        "    Returns:\n",
        "      Single embedding result for patch.\n",
        "    \"\"\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2GRjlAPQQdm"
      },
      "source": [
        "### Example: Generating an Five Patch Mean Ensemble Embedding for a 512 pixel x 512 pixel DICOM Patch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WWpkmxuQRV2"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import dicom_web_interface\n",
        "from ez_wsi_dicomweb import dicom_slide\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "from ez_wsi_dicomweb import patch_embedding_ensemble_methods\n",
        "import ez_wsi_dicomweb.ml_toolkit.dicom_path as dicom_path\n",
        "\n",
        "# Defines DICOM image stored within a Google DICOM store.\n",
        "DATASET_PROJECT_ID = 'hai-cd3-foundations'\n",
        "DATASET_LOCATION = 'us-west1'\n",
        "DATASET_ID = 'pathology'\n",
        "STORE_ID  = 'camelyon'\n",
        "STUDY_INSTANCE_UID  = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461'\n",
        "SERIES_INSTANCE_UID = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463'\n",
        "\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging.\n",
        "series_path = dicom_path.FromString(f'https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}')\n",
        "\n",
        "# Crediental factory that provides EZ-WSI with credentials to access DICOM imaging metadata.\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide, retrieves slide metadata but not slide imaging.\n",
        "ds = dicom_slide.DicomSlide(path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf))\n",
        "\n",
        "# Request a single patch of imaging from the highest magnfication.\n",
        "# Dimensions of the patch exceed the endpoint input requirements.\n",
        "patch = ds.get_patch(level=ds.native_level, x=43000, y=10000, width=512, height=512)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes the input patch of arbitrary size and breaks it into 5 224 x 224 pixel\n",
        "# patches which are sampled at the corners and center of each patch.\n",
        "ensemble_method = patch_embedding_ensemble_methods.FivePatchMeanEnsemble()\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch, ensemble_method)\n",
        "\n",
        "# Display image (Not required purely to illustrate source imaging for embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in embeding\n",
        "print (embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU6kIZt0QtXj"
      },
      "source": [
        "### Example: Generating an Five Patch Mean Ensemble Embedding for a 512 pixel x 512 pixel Google Cloud Storage Image Patch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FOrHsM_Q5Tr"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "\n",
        "\n",
        "# Create a reference to an image stored on Google Cloud Storage\n",
        "# By default authenticates with default credientals.\n",
        "image = gcs_image.GcsImage('gs://healthai-us/pathology/example_large_patch.jpeg',\n",
        "                           credential_factory=credential_factory.NoAuthCredentialsFactory())\n",
        "\n",
        "# Define coordinates of image patch\n",
        "patch = image.get_patch(x=10, y=10, width=512, height=512)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes the input patch of arbitrary size and breaks it into 5 224 x 224 pixel\n",
        "# patches which are sampled at the corners and center of each patch.\n",
        "ensemble_method = patch_embedding_ensemble_methods.FivePatchMeanEnsemble()\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch, ensemble_method)\n",
        "# Display image (Not required purely to illustrate source imaging for embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in embeding\n",
        "print (embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NLUXaa5RTqN"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO5_p4waQC1K"
      },
      "source": [
        "### Example: Generating an Mean Ensemble Embedding for a 512 pixel x 512 pixel DICOM Patch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxBR_-uSySBZ"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import dicom_web_interface\n",
        "from ez_wsi_dicomweb import dicom_slide\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "from ez_wsi_dicomweb import patch_embedding_ensemble_methods\n",
        "import ez_wsi_dicomweb.ml_toolkit.dicom_path as dicom_path\n",
        "\n",
        "# Defines DICOM image stored within a Google DICOM store.\n",
        "DATASET_PROJECT_ID = 'hai-cd3-foundations'\n",
        "DATASET_LOCATION = 'us-west1'\n",
        "DATASET_ID = 'pathology'\n",
        "STORE_ID  = 'camelyon'\n",
        "STUDY_INSTANCE_UID  = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344594461'\n",
        "SERIES_INSTANCE_UID = '1.3.6.1.4.1.11129.5.7.999.186491099540.79362771.1709051344626463'\n",
        "\n",
        "\n",
        "# Full path to DICOM store and DICOM series containing whole slide imaging.\n",
        "series_path = dicom_path.FromString(f'https://healthcare.googleapis.com/v1/projects/{DATASET_PROJECT_ID}/locations/{DATASET_LOCATION}/datasets/{DATASET_ID}/dicomStores/{STORE_ID}/dicomWeb/studies/{STUDY_INSTANCE_UID}/series/{SERIES_INSTANCE_UID}')\n",
        "\n",
        "# Crediental factory that provides EZ-WSI with credentials to access DICOM imaging metadata.\n",
        "dcf = credential_factory.DefaultCredentialFactory()\n",
        "\n",
        "# Create interface to slide, retrieves slide metadata but not slide imaging.\n",
        "ds = dicom_slide.DicomSlide(path=series_path, dwi=dicom_web_interface.DicomWebInterface(dcf))\n",
        "\n",
        "# Request a single patch of imaging from the highest magnfication.\n",
        "# Dimensions of the patch exceed the endpoint input requirements.\n",
        "patch = ds.get_patch(level=ds.native_level, x=43000, y=10000, width=512, height=512)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes the input patch of abritrary size and breaks it into 224 x 224 pixel\n",
        "# patches which are sampled regularlly across the with a horizontal and vertical\n",
        "# spacing of 250 pixels, (upper left corner to adjacent patch upper left corner)\n",
        "ensemble_method = patch_embedding_ensemble_methods.MeanPatchEmbeddingEnsemble(250, 250)\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch, ensemble_method)\n",
        "\n",
        "# Display image (Not required purely to illustrate source imaging for embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in embeding\n",
        "print (embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y59MFYNHw4Pi"
      },
      "source": [
        "### Example: Generating an Mean Ensemble Embedding for a 512 pixel x 512 pixel Google Cloud Storage Image Patch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INI-pvedduGD"
      },
      "outputs": [],
      "source": [
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "\n",
        "\n",
        "# Create a reference to an image stored on Google Cloud Storage\n",
        "# By default authenticates with default credientals.\n",
        "image = gcs_image.GcsImage('gs://healthai-us/pathology/example_large_patch.jpeg',\n",
        "                           credential_factory=credential_factory.NoAuthCredentialsFactory())\n",
        "\n",
        "# Define coordinates of image patch\n",
        "patch = image.get_patch(x=10, y=10, width=512, height=512)\n",
        "\n",
        "# Defines the endpoint that will called to generate the embedding.\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()\n",
        "\n",
        "# Takes the input patch of abritrary size and breaks it into 224 x 224 pixel\n",
        "# patches which are sampled regularlly across the with a horizontal and vertical\n",
        "# spacing of 250 pixels, (upper left corner to adjacent patch upper left corner)\n",
        "ensemble_method = patch_embedding_ensemble_methods.MeanPatchEmbeddingEnsemble(250, 250)\n",
        "\n",
        "# Takes a patch (DicomPatch or GcsPatch) and returns an embedding.\n",
        "embedding = patch_embedding.get_patch_embedding(endpoint, patch, ensemble_method)\n",
        "# Display image (Not required purely to illustrate source imaging for embedding)\n",
        "render_patch(patch)\n",
        "\n",
        "# Display first 12 values in embeding\n",
        "print (embedding[:12])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McsuQlQYSEOe"
      },
      "source": [
        "# \u003ca name=\"endpoints\"\u003eEmbedding Endpoints\u003c/a\u003e\n",
        "\n",
        "All embedding generation functions and classes require the endpoint parameter. The the endpoint is a high level abstraction which defines the underlying interface through which EZ-WSI requests and receives embeddings. EZ-WSI provides three endpoint implementations: V2PatchEmbeddingEndpoint, LocalEndpoint, and V1PatchEmbeddingEndpoint. Additional endpoints can be implemented by writing a custom implementation that is derived from patch_embedding_endpoints.AbstractPatchEmbeddingEndpoint.\n",
        "\n",
        "A description of the three endpoints provided by EZ-WSI follow:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhZiJD8PUhhr"
      },
      "source": [
        "## V2PatchEmbeddingEndpoint\n",
        "\n",
        "The V2PatchEmbeddingEndpoint defines an endpoint connection to the just launched V2 Pathology Embeddings API. V2 endpoint supports embedding generation for patch requests for DICOM imaging, imaging stored on Google Cloud Storage, and imaging defined from local data sources. The V2Patch embedding endpoint supports combining requests from multiple sources from within a single batch embedding request. The V2 endpoint supports server side resizing and ICC color profile normalization.\n",
        "\n",
        "```\n",
        "class V2PatchEmbeddingEndpoint(_PatchEmbeddingEndpointBase):\n",
        "  \"\"\"Implements Patch embedding V2 API.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      endpoint_api_version: str = 'v1',  # Vertex API version\n",
        "      project_id: str = 'hai-cd3-foundations',\n",
        "      endpoint_location: str = 'us-central1',\n",
        "      endpoint_id: str = '162',\n",
        "      max_threads: int = _DEFAULT_ENDPOINT_THREADS,\n",
        "      max_patches_per_request: int = _DEFAULT_MAX_PATCHES_PER_REQUEST,\n",
        "      retry_count: int = _DEFAULT_RETRY_COUNT,\n",
        "      icc_profile_normalization: IccProfileNormalization = (\n",
        "          IccProfileNormalization.NONE\n",
        "      ),\n",
        "      send_gcs_patch_bytes_from_client_to_server: bool = False,\n",
        "      require_fully_in_source_image: bool = True,\n",
        "      credential_factory: Optional[\n",
        "          credential_factory_module.AbstractCredentialFactory\n",
        "      ] = None,\n",
        "  ):\n",
        "```\n",
        "\n",
        "Constructor parameters:\n",
        "\n",
        "- \u003cu\u003eendpoint_api_version\u003c/u\u003e: The API version of the VertexAI endpoint hosting the V2 endpoint. Defaults to v1. (**Recommended** leave set to default value)\n",
        "\n",
        "- \u003cu\u003eproject_id\u003c/u\u003e: The Google Cloud Project Id of the project hosting the Vertex AI Endpoint.\n",
        "\n",
        "- \u003cu\u003eendpoint_id\u003c/u\u003e: The endpoint Id of the VertexAI endpoint hosting the Pathology 2.0 endpoint.\n",
        "\n",
        "- \u003cu\u003emax_threads\u003c/u\u003e:To accelerate embedding generation for large batch jobs, EZ-WSI will split embedding requests across multiple threads, request embeddings in parallel from the endpoint and then recombine the results. Parallelization happens transparently when using the EZ-WSIs embedding interfaces. The maximum number of threads to launch when processing embedding requests; defaults to 5.\n",
        "\n",
        "- \u003cu\u003emax_patches_per_request\u003c/u\u003e: Maximum number of patches to request in one endpoint request. Defaults to 100. Requests which exceed this size are transparently split and processed across multiple requests. The V2 endpoint has an absolute maximum setting of 3,000 patches per-request.\n",
        "\n",
        "- \u003cu\u003eretry_count\u003c/u\u003e: Number of times the endpoint will retry failed requests.\n",
        "\n",
        "- \u003cu\u003esend_gcs_patch_bytes_from_client_to_server\u003c/u\u003e: Optimization flag, defaults to False (Recommended setting), if set to True then image patches referencing imaging stored on Google Cloud Storage that have retrieved the imaging pixel data prior to the embedding request may include the retrieved imaging bytes within the embedding request to enable the endpoint to process the imaging without additional Google Cloud Storage transactions. In most cases enabling this \u003cu\u003ewill not improve performance\u003c/u\u003e. Enabling this setting may be advantageous if EZ-WSI is being run from an environment with exceptionally high upload bandwidth.\n",
        "\n",
        "- \u003cb\u003e\u003cu\u003eicc_profile_normalization\u003c/u\u003e\u003c/b\u003e: The V2 endpoint can perform ICC color profile normalization to transform patch imaging into a common color space prior to embedding generation. This parameter accepts an enum value that defines a target ICC Color profile that imaging containing an ICC Color profile will be transformed to prior to embedding generation. The V2 endpoint supports transforming imaging to the ICC Color Profiles defined as rendering parameters in the DICOM Standard (sRGB, AdobeRgb, and RommRGB). The parameter defaults to None indicating that no ICC color profile normalization will be performed.\n",
        "\n",
        "```\n",
        "class IccProfileNormalization(enum.Enum):\n",
        "  \"\"\"ICC Profile To Normalize Embedding Patches To.\"\"\"\n",
        "\n",
        "  NONE = 'NONE'\n",
        "  SRGB = 'SRGB'\n",
        "  ADOBERGB = 'ADOBERGB'\n",
        "  ROMMRGB = 'ROMMRGB'\n",
        "```\n",
        "\n",
        "\u003cb\u003eWhy is this important?\u003c/b\u003e\n",
        "\n",
        "Whole slide imaging is commonly acquired within the color space of the slide scanners. The color space of slide scanners varies within vendors, and across vendors. The effect of this is that when viewed on a monitor or processed by a ML model the identical slide scanned on two different systems may appear visually different (monitor) or quantitatively different by ML. ICC profile normalization transforms the color values within the imaging into a common space. This transformation should make imaging that is captured by calibrated systems with different optical characteristics more similar. Performing ICC Profile normalization may help make ML more generalizable across scanners.\n",
        "\n",
        "- \u003cu\u003erequire_fully_in_source_image\u003c/u\u003e: Requires that patch coordinates fall within the source image coordinates.  Defaults to True. If True (default) then an error will be returned for embedding requests which define invalid patches. If false (not recommended) the non-overlapping portion of a patch will be set to black RGB (0, 0, 0).\n",
        "\n",
        "- \u003cu\u003ecredential_factory\u003c/u\u003e: The credential factory defines how the OAuth credentials are obtained to connect to the embedding endpoint. By default the endpoint will use the application default credentials associated with the user / service account running EZ-WSI to connect to the Vertex AI endpoint. In most cases this parameter should be left set to this default setting. Note, these credentials \u003cu\u003edo not define the credentials used by the endpoint to retrieve imaging\u003c/u\u003e. Image retrieval credentials are defined by credential_factorys defined on the interfaces used to generate patches from cloud imaging (GcsImage or DicomSlide) classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qPXZjqlUaXl"
      },
      "source": [
        "## LocalEndpoint\n",
        "\n",
        "The LocalEndpoint defines an endpoint that can run locally within the machine executing EZ-WSI. If processing data from Cloud the local endpoint will retrieve imaging data. The local endpoint supports embedding generation for patch requests from DICOM imaging, imaging stored on Google Cloud Storage, and imaging defined from local data sources. The LocalEndpoint supports combining requests from multiple sources from within a single batch embedding request. The local endpoint supports image resizing and ICC color profile normalization.\n",
        "\n",
        "** Performance Tip **\n",
        "\n",
        "The local endpoint will typically have significantly lower performance when working from cloud data sources than the V2PatchEmbeddingEndpoint. The local endpoint may offer better performance than the cloud endpoints when processing data that is stored locally.\n",
        "\n",
        "```\n",
        "class LocalEndpoint(AbstractPatchEmbeddingEndpoint[np.ndarray]):\n",
        "  \"\"\"Endpoint for generating embeddings with a locally loaded model.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      model: Callable[[np.ndarray], np.ndarray],\n",
        "      icc_profile_normalization: IccProfileNormalization = (\n",
        "          IccProfileNormalization.NONE\n",
        "      ),\n",
        "      patch_width: int = 224,\n",
        "      patch_height: int = 224,\n",
        "      require_fully_in_source_image: bool = True,\n",
        "      max_threads: int = _DEFAULT_ENDPOINT_THREADS,\n",
        "      retry_count: int = _DEFAULT_RETRY_COUNT,\n",
        "      max_patches_per_request: int = _DEFAULT_MAX_PATCHES_PER_REQUEST,\n",
        "      dicom_instance_icc_profile_cache_count: int = _DEFAULT_DICOM_INSTANCE_ICC_PROFILE_CACHE_COUNT,\n",
        "  ):\n",
        "```\n",
        "\n",
        "Constructor parameters:\n",
        "\n",
        "model: A python function or other callable that when called with a batch of patch imaging (numpy) returns image embeddings. The shape of the numpy data is (batch, height, width, 3).  \n",
        "\n",
        "- \u003cu\u003eicc_profile_normalization\u003c/u\u003e: The local endpoint can perform ICC color profile normalization. See the V2Endpoint documentation for more information on this parameter. Defaults to None.\n",
        "\n",
        "- \u003cu\u003epatch_width\u003c/u\u003e: The patch image width that the endpoint accepts. Defaults to 224. Parameter should be set to the value required by the model.\n",
        "\n",
        "- \u003cu\u003epatch_height\u003c/u\u003e: The patch image width that the endpoint accepts. Defaults to 224. Parameter should be set to the value required by the model.\n",
        "\n",
        "- \u003cu\u003erequire_fully_in_source_image\u003c/u\u003e: Requires that patch coordinates fall within the source image coordinates.  Defaults to True. If True (default) then an error will be returned for embedding requests which define invalid patches. If false (not recommended) the non-overlapping portion of a patch will be set to black RGB (0, 0, 0).\n",
        "\n",
        "- \u003cu\u003emax_threads\u003c/u\u003e:The maximum number of threads to use when retrieving data from the cloud; defaults to 5.\n",
        "\n",
        "- \u003cu\u003eretry_count\u003c/u\u003e: Number of times the endpoint will retry failed requests.\n",
        "\n",
        "- \u003cu\u003emax_patches_per_request\u003c/u\u003e: The maximum number of patches which will be processed at once. Batch requests which exceed this size will be split, executed in chunks, and then recombined. These operations occur transparently inside EZ-WSI.\n",
        "\n",
        "- \u003cu\u003edicom_instance_icc_profile_cache_count\u003c/u\u003e: The number of ICC color profiles to cache within the endpoint. When generating ICC Color Profile corrected embeddings from DICOM imaging stored within the cloud both the imaging (pixel frame data) and the ICC Color Profile will need to be retrieved by the local endpoint. Some WSI scanners, e.g. Leica, produce images with very large ICC color profiles (~12 MB). The ICC profile cache temporarily stores the DICOM ICC Profiles being used to avoid repeated profile retrieval. This parameter has no effect if the imaging does not contain an ICC Color Profile or the patches are defined from a source other than DICOM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVKCdZ0aUaJh"
      },
      "source": [
        "## V1PatchEmbeddingEndpoint (Not Recommended)\n",
        "\n",
        "The V1PatchEmbeddingEndpoint defines an endpoint connection to the V1 Pathology Embeddings API endpoint. The V1 endpoint is not recommended for general use. The V1 endpoint supports processing embedding requests on imaging stored within a Google DICOM store or on Google Cloud Storage. The V1 Google Research endpoints that process these requests are different. As a result a single instance of the EZ-WSI V1 endpoint can be configured to communicate with a DicomStore Endpoint or Google Cloud Storage Endpoint, but not both. The V1 endpoints do not support image resizing, icc color profile correction, or processing locally stored data.\n",
        "\n",
        "```\n",
        "class V1PatchEmbeddingEndpoint(_PatchEmbeddingEndpointBase):\n",
        "  \"\"\"Implements Patch embedding V1 API.\"\"\"\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      endpoint_api_version: str = 'v1',  # Vertex API version\n",
        "      project_id: str = 'hai-cd3-foundations',\n",
        "      endpoint_location: str = 'us-central1',\n",
        "      endpoint_id: str = '160',\n",
        "      max_threads: int = _DEFAULT_ENDPOINT_THREADS,\n",
        "      max_patches_per_request: int = _DEFAULT_MAX_PATCHES_PER_REQUEST,\n",
        "      retry_count: int = _DEFAULT_RETRY_COUNT,\n",
        "      send_gcs_patch_bytes_from_client_to_server: bool = False,\n",
        "      credential_factory: Optional[\n",
        "          credential_factory_module.AbstractCredentialFactory\n",
        "      ] = None,\n",
        "  ):\n",
        "```\n",
        "\n",
        "Constructor parameters:\n",
        "\n",
        "- \u003cu\u003eendpoint_api_version\u003c/u\u003e: The API version of the VertexAI endpoint hosting the V1 endpoint. Defaults to v1. (**Recommended** leave set to default value)\n",
        "\n",
        "- \u003cu\u003eproject_id\u003c/u\u003e: The Google Cloud Project Id, name, of the project hosting the Vertex AI Endpoint.\n",
        "\n",
        "- \u003cu\u003eendpoint_id\u003c/u\u003e: The endpoint Id of the VertexAI endpoint hosting the Pathology 1.0 endpoint.\n",
        "\n",
        "- \u003cu\u003emax_threads\u003c/u\u003e:To accelerate embedding generation for large batch jobs, EZ-WSI will split embedding requests across multiple threads, request embeddings in parallel from the endpoint and then recombine the results. Parallelization happens transparently when using the EZ-WSIs embedding interfaces. The maximum number of threads to launch when processing embedding requests; defaults to 5.\n",
        "\n",
        "- \u003cu\u003emax_patches_per_request\u003c/u\u003e: Maximum number of patches to request in one endpoint request. Defaults to 100. Requests which exceed this size are transparently split and processed across multiple requests. The V1 endpoint has an absolute maximum setting of 3,000 patches per-request.\n",
        "\n",
        "- \u003cu\u003eretry_count\u003c/u\u003e: Number of times the endpoint will retry failed requests.\n",
        "\n",
        "- \u003cu\u003esend_gcs_patch_bytes_from_client_to_server\u003c/u\u003e: Optimization flag, defaults to False (Recommended setting), if set to True then image patches referencing imaging stored on Google Cloud Storage that have retrieved the imaging pixel data prior to the embedding request may include the retrieved imaging bytes within the embedding request to enable the endpoint to process the imaging without additional Google Cloud Storage transactions. In most cases enabling this \u003cu\u003ewill not improve performance\u003c/u\u003e. Enabling this setting may be advantageous if EZ-WSI is being run from an environment with exceptionally high upload bandwidth.\n",
        "\n",
        "- \u003cu\u003ecredential_factory\u003c/u\u003e: The credential factory defines how the OAuth credentials are obtained to connect to the embedding endpoint. By default the endpoint will use the application default credentials associated with the user / service account running EZ-WSI to connect to the Vertex AI endpoint. In most cases this parameter should be left set to this default setting. Note, these credentials \u003cu\u003edo not define the credentials used by the endpoint to retrieve imaging\u003c/u\u003e. Image retrieval credientals are defined by credential_factorys defined on the interfaces used to generate patches from cloud imaging (GcsImage or DicomSlide) classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoYRRzSF0hm2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/pathology/v2/getting_started.ipynb?workspaceId=philbrik:ez_wsi_embeddings::citc",
          "timestamp": 1727969011876
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/pathology/v2/getting_started.ipynb?workspaceId=philbrik:ez_wsi_embeddings::citc",
          "timestamp": 1727931749636
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/pathology/v2/getting_started.ipynb?workspaceId=philbrik:ez_wsi_embeddings::citc",
          "timestamp": 1727905578123
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/pathology/v2/getting_started.ipynb?workspaceId=philbrik:ez_wsi_embeddings::citc",
          "timestamp": 1727905391058
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/pathology/v2/simple-linear-classifier-demo.ipynb?workspaceId=philbrik:ez_wsi_embeddings::citc",
          "timestamp": 1727302201355
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/pathology/simple-linear-classifier-demo.ipynb?workspaceId=philbrik:embedding_example::citc",
          "timestamp": 1726884269654
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/pathology/simple-linear-classifier-demo.ipynb",
          "timestamp": 1726882804846
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
