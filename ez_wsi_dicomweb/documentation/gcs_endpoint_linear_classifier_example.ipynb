{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5eciEDyU6BP"
      },
      "source": [
        "~~~\n",
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "~~~\n",
        "# Train a Digital Pathology Linear Classifier From Images Stored on Google Cloud Storage (GCS)\n",
        "\n",
        "This notebook is a demonstration of generating and using embeddings from the Path Foundation API to train a linear classifier. This API enables users to compute embeddings for histopathology images. Note: This notebook is for API demonstration purposes only. As with all machine-learning use-cases it is critical to consider training and evaluation datasets that reflect the expected distribution of the intended use case.\n",
        "\n",
        "**Additional details**: For this demo, patches sampled from whole slide images (WSIs) are downloaded from Google Cloud Storage. A subset of the patches will be sampled randomly from across all available slides and embeddings will be generated via the Path Foundation model.\n",
        "\n",
        "**Dataset**: This notebook uses the [CAMELYON16](https://camelyon16.grand-challenge.org/) dataset, which contains WSIs from lymph node specimens with and without metastatic breast cancer. Any work that uses this dataset should consider additional details along with usage and citation requirements listed on [their website](https://camelyon17.grand-challenge.org/Data/).\n",
        "\n",
        "**Dataset citation**: Babak Ehteshami Bejnordi; Mitko Veta; Paul Johannes van Diest; Bram van Ginneken; Nico Karssemeijer; Geert Litjens; Jeroen A. W. M. van der Laak; and the CAMELYON16 Consortium. Diagnostic Assessment of Deep Learning Algorithms for Detection of Lymph Node Metastases in Women With Breast Cancer. JAMA. 2017;318(22):2199â€“2210. DOI: 10.1001/jama.2017.14585"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9E-VYsIGZLu"
      },
      "outputs": [],
      "source": [
        "# @title Pip install EZ-WSI DICOMweb\n",
        "%%capture\n",
        "!pip install --upgrade ez_wsi_dicomweb>=6.0.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaxxwnKG7opB"
      },
      "outputs": [],
      "source": [
        "# @title Retrieve list of images defined as representing cancer and benign imaging from Google Cloud Storage.\n",
        "import google.cloud.storage\n",
        "\n",
        "client = google.cloud.storage.Client.create_anonymous_client()\n",
        "bucket = google.cloud.storage.Bucket(name='healthai-us', client=client)\n",
        "\n",
        "# Patch imaging is statified by slide and stored within test and evaluation buckets\n",
        "# Retrieve a list of imaging stored in buckets, image bytes not retrieved here.\n",
        "cancer_imaging_training = list(\n",
        "    bucket.list_blobs(prefix='pathology/training/cancer')\n",
        ")\n",
        "benign_imaging_training = list(\n",
        "    bucket.list_blobs(prefix='pathology/training/benign')\n",
        ")\n",
        "cancer_imaging_eval = list(bucket.list_blobs(prefix='pathology/eval/cancer'))\n",
        "benign_imaging_eval = list(bucket.list_blobs(prefix='pathology/eval/benign'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US1lYjpwF6hh"
      },
      "outputs": [],
      "source": [
        "# @title Select a random subset of imaging for training and evaluation\n",
        "import random\n",
        "\n",
        "TRAINING_SIZE = 250\n",
        "EVAL_SIZE = 65\n",
        "\n",
        "# Randomize the image lists.\n",
        "random.shuffle(cancer_imaging_training)\n",
        "random.shuffle(benign_imaging_training)\n",
        "random.shuffle(cancer_imaging_eval)\n",
        "random.shuffle(benign_imaging_eval)\n",
        "\n",
        "# Take the 250 examples for training\n",
        "cancer_training = cancer_imaging_training[:TRAINING_SIZE]\n",
        "benign_training = benign_imaging_training[:TRAINING_SIZE]\n",
        "\n",
        "# Take the 65 examples for evaluation\n",
        "cancer_eval = cancer_imaging_eval[:EVAL_SIZE]\n",
        "benign_eval = benign_imaging_eval[:EVAL_SIZE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axippFnR8-iF"
      },
      "outputs": [],
      "source": [
        "# @title Authenticate notebook.\n",
        "from google.colab import auth\n",
        "\n",
        "if 'gcp_user_auth' not in globals():\n",
        "  # Authenticate user for access to Research Embedding Endpoint.\n",
        "  # There will be a popup asking you to sign in with your user account\n",
        "  # and approve access.\n",
        "  auth.authenticate_user()\n",
        "  global gcp_user_auth\n",
        "  gcp_user_auth = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBFMaZpyLHJB"
      },
      "outputs": [],
      "source": [
        "# @title Define Cloud Endpoint used to Generate Embeddings.\n",
        "from ez_wsi_dicomweb import patch_embedding_endpoints\n",
        "\n",
        "endpoint = patch_embedding_endpoints.V2PatchEmbeddingEndpoint()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fut_v1DIFcTB"
      },
      "outputs": [],
      "source": [
        "# @title Generate embeddings for pathology Embedding Endpoint\n",
        "#\n",
        "# Patch embeddings are computed here.\n",
        "\n",
        "import concurrent.futures\n",
        "from typing import List\n",
        "from ez_wsi_dicomweb import credential_factory\n",
        "from ez_wsi_dicomweb import gcs_image\n",
        "from ez_wsi_dicomweb import patch_embedding\n",
        "from ez_wsi_dicomweb import patch_embedding_types\n",
        "\n",
        "\n",
        "\n",
        "def generate_embeddings(patches) -> List[patch_embedding_types.EmbeddingResult]:\n",
        "  \"\"\"Returns embeddings for list (patches) of images using the endpoint defined.\"\"\"\n",
        "  # Performance tip. Defining the image dimensions improves performance by\n",
        "  # enabling the client to know the dimensions of input imaging without having\n",
        "  # to retrieve the imaging. The patch imaging used in this Colab was saved as\n",
        "  # 224 x 224 pixels patches to match the endpoint input dimensions. If the\n",
        "  # defined image dimension does not match the actual image dimension the\n",
        "  # endpoint generating the image will resize the image to match the defined\n",
        "  # dimensions.\n",
        "  #\n",
        "  # For this colab embeddings are generated from the whole image.\n",
        "  embedding_result_iterator = patch_embedding.gcs_images_to_embeddings(\n",
        "          endpoint,\n",
        "          patches,\n",
        "          image_dimensions=gcs_image.ImageDimensions(224, 224),\n",
        "          credential_factory=credential_factory.NoAuthCredentialsFactory(),\n",
        "      )\n",
        "  return list(embedding_result_iterator)\n",
        "\n",
        "\n",
        "# Requeset embeddings in parallel for all four datasets.\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
        "  results = list(\n",
        "      executor.map(\n",
        "          generate_embeddings,\n",
        "          [cancer_training, benign_training, cancer_eval, benign_eval],\n",
        "      )\n",
        "  )\n",
        "training_cancer_embeddings = results[0]\n",
        "training_benign_embeddings = results[1]\n",
        "eval_cancer_embeddings = results[2]\n",
        "eval_benign_embeddings = results[3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ovli6nlc7c7R"
      },
      "outputs": [],
      "source": [
        "# @title Organize embeddings for ML training\n",
        "import os\n",
        "from typing import Sequence, Tuple\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_embeddings(\n",
        "    embedding_results: Sequence[patch_embedding_types.EmbeddingResult],\n",
        ") -> np.ndarray:\n",
        "  \"\"\"Returns numpy array of embeddings returned in embedding results list.\"\"\"\n",
        "  return np.array([e.embedding for e in embedding_results])\n",
        "\n",
        "\n",
        "def get_slide_id(\n",
        "    embedding_results: Sequence[patch_embedding_types.EmbeddingResult],\n",
        ") -> List[str]:\n",
        "  \"\"\"Returns list of patch slide ids encoded into patch GCS file name.\n",
        "\n",
        "  Patch file names were encoded with an id value that identifies the ID of the\n",
        "  the slide they came from, extract IDs from file names to use a clustering\n",
        "  index in StratifiedGroupKFold\n",
        "  \"\"\"\n",
        "  slide_id = []\n",
        "  # for each embedding result get the images GCS URI\n",
        "  for uri in [e.patch.source.uri for e in embedding_results]:\n",
        "    # split the file name into parts and extract the slide id\n",
        "    filename = uri.split('/')[-1]\n",
        "    slide_id.append(os.path.splitext(filename)[0].split('_')[-1])\n",
        "  return slide_id\n",
        "\n",
        "\n",
        "def concatenate_training_data_and_build_training_labels(\n",
        "    cancer: Sequence[patch_embedding_types.EmbeddingResult],\n",
        "    benign: Sequence[patch_embedding_types.EmbeddingResult],\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "  \"\"\"Concatenate cancer and benign examples into and generate label data.\"\"\"\n",
        "  data = np.concatenate([get_embeddings(cancer), get_embeddings(benign)])\n",
        "  labels = np.concatenate((np.ones(len(cancer)), np.zeros(len(benign))))\n",
        "  return data, labels\n",
        "\n",
        "\n",
        "# Embeddings and training lables\n",
        "training_embeddings, training_labels = (\n",
        "    concatenate_training_data_and_build_training_labels(\n",
        "        training_cancer_embeddings, training_benign_embeddings\n",
        "    )\n",
        ")\n",
        "# Slide Ids for clustering.\n",
        "slide_ids = get_slide_id(training_cancer_embeddings)\n",
        "slide_ids.extend(get_slide_id(training_benign_embeddings))\n",
        "\n",
        "# Generate evaluation embeddings and labels\n",
        "eval_embeddings, eval_labels = (\n",
        "    concatenate_training_data_and_build_training_labels(\n",
        "        eval_cancer_embeddings, eval_benign_embeddings\n",
        "    )\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CIgAshDQE__"
      },
      "outputs": [],
      "source": [
        "# @title Train a linear classifier using the embeddings\n",
        "import warnings\n",
        "import sklearn.linear_model\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.pipeline\n",
        "import sklearn.preprocessing\n",
        "\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter('ignore')\n",
        "  clf_pipeline = sklearn.pipeline.Pipeline([\n",
        "      ('scaler', sklearn.preprocessing.StandardScaler()),\n",
        "      (\n",
        "          'logreg',\n",
        "          sklearn.model_selection.GridSearchCV(\n",
        "              sklearn.linear_model.LogisticRegression(\n",
        "                  random_state=0,\n",
        "                  multi_class='ovr',\n",
        "                  verbose=False,\n",
        "              ),\n",
        "              cv=sklearn.model_selection.StratifiedGroupKFold(n_splits=5).split(\n",
        "                  training_embeddings, y=training_labels, groups=slide_ids\n",
        "              ),\n",
        "              param_grid={'C': np.logspace(start=-4, stop=4, num=10, base=10)},\n",
        "              scoring='roc_auc_ovr',\n",
        "              refit=True,\n",
        "          ),\n",
        "      ),\n",
        "  ]).fit(training_embeddings, training_labels)\n",
        "\n",
        "  test_predictions = clf_pipeline.predict_proba(eval_embeddings)[:, 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEiAoRwV7V_v"
      },
      "outputs": [],
      "source": [
        "# @title Evaluate the linear classifiers performance using the eval patches\n",
        "sklearn.metrics.roc_auc_score(eval_labels, test_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxgKZgWqjAOM"
      },
      "outputs": [],
      "source": [
        "# @title Plot the ROC Curve\n",
        "\n",
        "display = sklearn.metrics.RocCurveDisplay.from_predictions(\n",
        "    eval_labels, test_predictions, name=\"Tumor Classifier\"\n",
        ")\n",
        "display.ax_.set_title(\"ROC of Tumor Classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xjc23U507MUc"
      },
      "outputs": [],
      "source": [
        "# @title Find Youden's index for threshold selection\n",
        "\n",
        "thresholds = np.linspace(0, 1, 100)\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "for threshold in thresholds:\n",
        "  predictions = test_predictions > threshold\n",
        "  sensitivities.append(sklearn.metrics.recall_score(eval_labels, predictions))\n",
        "  specificities.append(\n",
        "      sklearn.metrics.recall_score(eval_labels == 0, predictions == 0)\n",
        "  )\n",
        "index = np.argmax(np.array(sensitivities) + np.array(specificities))\n",
        "best_threshold = thresholds[index]\n",
        "sens = sensitivities[index]\n",
        "spec = specificities[index]\n",
        "print(\n",
        "    f\"Best threshold: {round(best_threshold,2)}. Sensitivity is\"\n",
        "    f\" {round(sens*100,2)}% and Specificity is {round(spec*100,2)}% \"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17s-mvrW7IT7"
      },
      "outputs": [],
      "source": [
        "# @title Show the results in a table\n",
        "import pandas as pd\n",
        "\n",
        "eval_embeddings_obj = eval_cancer_embeddings + eval_benign_embeddings\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    {'ground_truth': eval_labels, 'model_score': test_predictions}\n",
        ")\n",
        "df['tumor_prediction'] = df['model_score'] > best_threshold\n",
        "df['embeddings'] = [e.embedding for e in eval_embeddings_obj]\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es9ZvZYe6utq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def render_patch_from_embedding(\n",
        "    patch: gcs_image.GcsPatch, plot_name: str = ''\n",
        ") -> None:\n",
        "  patch_bytes = patch.image_bytes()\n",
        "  plt.figure(figsize=(2, 2))\n",
        "  plt.imshow(patch_bytes)\n",
        "  plt.title(plot_name)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# @title Visualize True Positives\n",
        "def display_results(\n",
        "    tumor_prediction: bool, ground_truth: int, title: str\n",
        ") -> None:\n",
        "  df_tp = (\n",
        "      df[\n",
        "          (df['tumor_prediction'] == tumor_prediction)\n",
        "          & (df['ground_truth'] == ground_truth)\n",
        "      ]\n",
        "      .sort_values('model_score', ascending=False)\n",
        "      .head(5)\n",
        "  )\n",
        "  for index, row in df_tp.iterrows():\n",
        "    print(index)\n",
        "    print(f'model score is {row.model_score}')\n",
        "    render_patch_from_embedding(eval_embeddings_obj[index].patch, title)\n",
        "\n",
        "\n",
        "display_results(True, 1, 'True Positive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3uaFT3b68WQ"
      },
      "outputs": [],
      "source": [
        "# @title Visualize True Negatives\n",
        "display_results(False, 0, 'True Negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR6J7KN77CE7"
      },
      "outputs": [],
      "source": [
        "# @title Visualize False Positives\n",
        "display_results(True, 0, 'False Positive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vON3jeOj7ELU"
      },
      "outputs": [],
      "source": [
        "# @title Visualize False Negatives\n",
        "display_results(False, 1, 'False Negative')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rABNDxNkgWF5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/path_foundation/notebooks/gcs_endpoint_linear_classifier_example.ipynb?workspaceId=philbrik:GCP_colab::citc",
          "timestamp": 1730136141985
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/path_foundation/notebooks/gcs_endpoint_linear_classifier_example.ipynb?workspaceId=philbrik:GCP_colab::citc",
          "timestamp": 1730135424792
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/path_foundation/notebooks/gcs_endpoint_linear_classifier_example.ipynb?workspaceId=philbrik:GCP_colab::citc",
          "timestamp": 1730133922318
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/path_foundation/notebooks/gcs_endpoint_linear_classifier_example.ipynb",
          "timestamp": 1730133446459
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/path_foundation/notebooks/gcs_endpoint_linear_classifier_example.ipynb?workspaceId=philbrik:gcs_embeddings::citc",
          "timestamp": 1729780617968
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/path_foundation/notebooks/gcs_endpoint_linear_classifier_example.ipynb",
          "timestamp": 1729780416468
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/path_foundation/notebooks/gcs_endpoint_linear_classifier_example.ipynb?workspaceId=philbrik:gcs_linear_classifier::citc",
          "timestamp": 1729722902626
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/path_foundation/notebooks/gcs_endpoint_linear_classifier_example.ipynb?workspaceId=philbrik:gcs_linear_classifier::citc",
          "timestamp": 1729722375544
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/path_foundation/notebooks/gcs_endpoint_linear_classifier_example.ipynb?workspaceId=philbrik:gcs_linear_classifier::citc",
          "timestamp": 1729722166667
        },
        {
          "file_id": "/piper/depot/google3/third_party/health_foundations/path_foundation/notebooks/gcs_hugging_face_endpoint_linear_classifier_example.ipynb",
          "timestamp": 1729721308347
        },
        {
          "file_id": "1gObTnuoT18yyJ0v6x-yo9bsEYpiVAN6C",
          "timestamp": 1729656842640
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}